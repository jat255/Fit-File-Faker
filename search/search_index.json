{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"FIT File Faker","text":"<p>This application allows you to easily modify FIT files to make them appear to come from a Garmin device (Edge 830, currently) and upload them to Garmin Connect using the <code>garth</code> library. The FIT editing is done using Stages Cycling's <code>fit_tool</code> library.</p> <p>Support This Project</p> <p>If FIT File Faker saves you time or enhances your training workflow, consider buying me a coffee \u2615. Your support helps maintain and improve this project!</p> <p>Additionally, it can be run in a \"monitor\" mode that will watch a folder for new FIT files and will automatically edit/upload them as they are produced. One potential application of this mode is to have the tool auto-start on the computer that you use for indoor training, so rides are automatically uploaded to Garmin Connect when you finish.</p>"},{"location":"#overview","title":"Overview","text":"<p>The primary motivation for this tool came from the fact that that TrainingPeaks Virtual (previously indieVelo) does/did not support automatic uploading to Garmin Connect. The files can be manually uploaded after the fact, but since they are not \"from Garmin\", they will not be used to calculate Garmin's Training Effect, which is used for suggested workouts and other features, especially if you have a watch or cycling computer that uses these features.</p> <p>By changing the FIT file to appear to come from a Garmin device, those features are enabled.</p> <p>Use Cases</p> <p>Other users have reported using this tool to edit FIT files produced by:</p> <ul> <li>Zwift: Upload to Garmin Connect so activities count towards badges and challenges</li> <li>TrainingPeaks Virtual: Enable Garmin's Training Effect calculations</li> <li>MyWhoosh: Similar compatibility benefits</li> <li>Hammerhead Karoo: Enhanced Garmin Connect integration</li> <li>COROS Dura: Enhanced Garmin Connect integration</li> </ul>"},{"location":"#contributors","title":"Contributors","text":"<ul> <li>jat255: Primary author</li> <li>benjmarshall: bug fixes, monitor mode, and other improvements</li> <li>Kellett: support for Zwift FIT files</li> <li>lrybak: support for Hammerhead Karoo files</li> <li>dermarzel: support for MyWhoosh files</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Requirements</p> <p>Python 3.12 or higher is required. If your system Python is older, use pyenv or uv to manage locally installed versions.</p> <p>This tool works cross-platform on Windows, macOS, and Linux (primarily developed on Linux).</p> uv (Recommended)pipxpipDevelopment <p>If you have uv installed:</p> <pre><code>uv tool install fit-file-faker\n</code></pre> <p>This installs the tool and makes <code>fit-file-faker</code> available on your PATH.</p> <p>If you have pipx installed:</p> <pre><code>pipx install fit-file-faker\n</code></pre> <p>This installs the tool and makes <code>fit-file-faker</code> available on your PATH.</p> <p>Install manually using pip in a virtual environment:</p> <pre><code>python -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\npip install fit-file-faker\n</code></pre> <p>The pip package installs a script named <code>fit-file-faker</code> that should be available on your path when the virtual environment is activated.</p> <p>For development, clone the repo and use uv:</p> <pre><code>git clone https://github.com/jat255/Fit-File-Faker.git\ncd Fit-File-Faker\nuv sync  # Installs all dependencies\n</code></pre> <p>Pre-commit hooks:</p> <p>The project uses pre-commit to run code quality checks. After cloning and running <code>uv sync</code>:</p> <pre><code>uv run pre-commit install\n</code></pre> <p>This automatically runs <code>ruff check</code> and <code>ruff format</code> on staged files before each commit.</p> <p>Run hooks manually on all files:</p> <pre><code>uv run pre-commit run --all-files\n</code></pre>"},{"location":"#configuration","title":"Configuration","text":"<p>The script uses a configuration file named <code>.config.json</code> stored in your system's user config directory (as determined by the <code>platformdirs</code> library).</p> <p>Example configuration:</p> <pre><code>{\n  \"garmin_username\": \"username\",\n  \"garmin_password\": \"password\",\n  \"fitfiles_path\": \"C:\\\\Users\\\\username\\\\Documents\\\\TPVirtual\\\\0123456789ABCDEF\\\\FITFiles\"\n}\n</code></pre> <p>Initial Setup</p> <p>The best way to create your config file is to run the interactive setup with the <code>-s</code> flag:</p> <pre><code>fit-file-faker -s\n</code></pre> <p>This will prompt you for:</p> <ul> <li>Garmin username</li> <li>Garmin password</li> <li>TrainingPeaks Virtual data folder (auto-detected on Windows/macOS)</li> </ul> <p>Example setup session:</p> <pre><code>$ fit-file-faker -s\n\n[16:02:04] WARNING  Required value \"garmin_username\" not found in config                                                                                                                            config.py:106\n? Enter value to use for \"garmin_username\" jat255\n[16:02:06] WARNING  Required value \"garmin_password\" not found in config                                                                                                                            config.py:106\n? Enter value to use for \"garmin_password\" ************\n[16:02:09] WARNING  Required value \"fitfiles_path\" not found in config                                                                                                                              config.py:106\n           INFO     Getting FITFiles folder                                                                                                                                                         config.py:169\n? Found TP Virtual User directory at \"/Users/user/TPVirtual/1234567890abcdef\", is this correct?  yes\n[16:02:17] INFO     Found TP Virtual User directory: \"/Users/user/TPVirtual/1234567890abcdef\", setting \"fitfiles_path\" in config file                                                               config.py:196\n           INFO     Config file is now:                                                                                                                                                             config.py:155\n                    {\n                      \"garmin_username\": \"username\",\n                      \"garmin_password\": \"&lt;**hidden**&gt;\",\n                      \"fitfiles_path\": \"/Users/user/TPVirtual/1234567890abcdef/FITFiles\"\n                    }\n           INFO     Config file has been written to \"/Users/user/Library/Application Support/FitFileFaker/.config.json\", now run one of the other options to start editing/uploading files!            app.py:289\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#command-line-options","title":"Command-line Options","text":"<p>To see all available options:</p> <pre><code>fit-file-faker -h\n</code></pre> <pre><code>usage: fit-file-faker [-h] [-s] [-u] [-ua] [-p] [-m] [-d] [-v] [input_path]\n\nTool to add Garmin device information to FIT files and upload them to Garmin Connect. Currently, only FIT files produced by TrainingPeaks Virtual (https://www.trainingpeaks.com/virtual/) and Zwift\n(https://www.zwift.com/) are supported, but it's possible others may work.\n\npositional arguments:\n  input_path           the FIT file or directory to process. This argument can be omitted if the 'fitfiles_path' config value is set (that directory will be used instead). By default, files will just be\n                       edited. Specify the \"-u\" flag to also upload them to Garmin Connect.\n\noptions:\n  -h, --help           show this help message and exit\n  -s, --initial-setup  Use this option to interactively initialize the configuration file (.config.json)\n  -u, --upload         upload FIT file (after editing) to Garmin Connect\n  -ua, --upload-all    upload all FIT files in directory (if they are not in \"already processed\" list)\n  -p, --preinitialize  preinitialize the list of processed FIT files (mark all existing files in directory as already uploaded)\n  -m, --monitor        monitor a directory and upload all newly created FIT files as they are found\n  -d, --dryrun         perform a dry run, meaning any files processed will not be saved nor uploaded\n  -v, --verbose        increase verbosity of log output\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<p>The default behavior loads a given FIT file and outputs a file named <code>path_to_file_modified.fit</code> that has been edited and can be manually imported to Garmin Connect:</p> <pre><code>fit-file-faker path_to_file.fit\n</code></pre> <p>If a directory is supplied rather than a single file, all FIT files in that directory will be processed in the same way.</p>"},{"location":"#upload-to-garmin-connect","title":"Upload to Garmin Connect","text":"<p>Supplying the <code>-u</code> option will attempt to upload the edited file to Garmin Connect. If your credentials are not stored in the configuration file, the script will prompt you for them.</p> <p>The OAuth credentials obtained for the Garmin web service will be stored in a directory named <code>.garth</code> in your system's user cache folder (as determined by <code>platformdirs</code>). See the <code>garth</code> library's documentation for details.</p> <pre><code>fit-file-faker -u path_to_file.fit\n</code></pre> <p>Example output:</p> <pre><code>[12:14:06] INFO     Activity timestamp is \"2024-05-21T17:15:48\"                              app.py:84\n           INFO     Saving modified data to path_to_file_modified.fit                        app.py:106\n[12:14:08] INFO     \u2705 Successfully uploaded \"path_to_file.fit\"                              app.py:137\n</code></pre>"},{"location":"#verbose-output","title":"Verbose Output","text":"<p>The <code>-v</code> flag can be used (with any of the other options) to provide more debugging output:</p> <pre><code>fit-file-faker -u path_to_file.fit -v\n</code></pre> <p>Example output:</p> <pre><code>[12:38:33] INFO     Activity timestamp is \"2024-05-21T17:15:48\"                              app.py:84\n           DEBUG    Record: 1 - manufacturer: 255 (\"DEVELOPMENT\") - product: 0 - garmin      app.py:55\n                    product: None (\"BLANK\")\n           DEBUG        Modifying values                                                     app.py:87\n           DEBUG        New Record: 1 - manufacturer: 1 (\"GARMIN\") - product: 3122 - garmin  app.py:55\n                    product: 3122 (\"GarminProduct.EDGE_830\")\n           DEBUG    Record: 14 - manufacturer: 32 (\"WAHOO_FITNESS\") - product: 40 - garmin   app.py:55\n                    product: None (\"BLANK\")\n           DEBUG        Modifying values                                                     app.py:97\n           DEBUG        New Record: 14 - manufacturer: 1 (\"GARMIN\") - product: 3122 - garmin app.py:55\n                    product: 3122 (\"GarminProduct.EDGE_830\")\n[12:38:34] DEBUG    Using stored Garmin credentials from \".garth\" directory                 app.py:118\n[12:38:35] INFO     \u2705 Successfully uploaded \"path_to_file.fit\"                             app.py:137\n</code></pre>"},{"location":"#upload-all-and-monitor-modes","title":"\"Upload All\" and \"Monitor\" Modes","text":""},{"location":"#upload-all","title":"Upload All","text":"<p>The <code>--upload-all</code> option will search for all FIT files either in the directory given on the command line, or in the one specified in the <code>fitfiles_path</code> config option. The script will:</p> <ol> <li>Compare the files found to a list of files already seen (stored in that directory's <code>.uploaded_files.json</code> file)</li> <li>Edit them</li> <li>Upload each to Garmin Connect</li> </ol> <p>The edited files will be written into a temporary file and discarded when the script finishes running, and the filenames will be stored into a JSON file so they are skipped the next time the script is run.</p>"},{"location":"#monitor-mode","title":"Monitor Mode","text":"<p>The <code>--monitor</code> option automates the upload all function by watching the filesystem in the specified directory for any new FIT files. It will continue running until the user interrupts the process by pressing <code>ctrl-c</code>.</p> <p>Example output when a new file named <code>new_fit_file.fit</code> is detected:</p> <pre><code>$ fit-file-faker --monitor /home/user/Documents/TPVirtual/0123456789ABCEDF/FITFiles\n\n[14:03:32] INFO     Using path \"/home/user/Documents/TPVirtual/                    app.py:561\n                    0123456789ABCEDF/FITFiles\" from command line input\n           INFO     Monitoring directory: \"/home/user/Documents/TPVirtual/         app.py:367\n                    0123456789ABCEDF/FITFiles\"\n[14:03:44] INFO     New file detected - \"/home/user/Documents/TPVirtual/           app.py:94\n                    0123456789ABCEDF/FITFiles/new_fit_file.fit\"; sleeping for\n                    5 seconds to ensure TPV finishes writing file\n[14:03:50] INFO     Found 1 files to edit/upload                                   app.py:333\n           INFO     Processing \"new_fit_file.fit\"                                  app.py:340\n           INFO     Processing \"/home/user/Documents/TPVirtual                     app.py:202\n                    sync/0123456789ABCEDF/FITFiles/new_fit_file.fit\"\n[14:03:58] INFO     Activity timestamp is \"2025-01-03T17:01:45\"                    app.py:223\n[14:03:59] INFO     Saving modified data to \"/tmp/tmpsn4gvpkh\"                     app.py:250\n[14:04:00] INFO     Uploading modified file to Garmin Connect                      app.py:346\n[14:04:01] INFO     Uploading \"/tmp/tmpsn4gvpkh\" using garth                       app.py:295\n^C[14:04:46] INFO     Received keyboard interrupt, shutting down monitor           app.py:372\n</code></pre> <p>Pre-initializing Uploaded Files</p> <p>If your TrainingPeaks Virtual user data folder already contains FIT files which you have previously uploaded to Garmin Connect using a different method, you can pre-initialize the list of uploaded files to avoid any possibility of uploading duplicates.</p> <p>Use the <code>--preinitialize</code> option to process a directory (defaults to the configured TrainingPeaks Virtual user data directory) and add all files to the list of previously uploaded files:</p> <pre><code>fit-file-faker --preinitialize\n</code></pre> <p>After this, any use of the <code>--upload-all</code> or <code>--monitor</code> options will ignore these pre-existing files.</p>"},{"location":"#already-uploaded-files","title":"Already Uploaded Files","text":"<p>Duplicate Detection</p> <p>If a file with the same timestamp already exists on the Garmin Connect account, Garmin will reject the upload. This script will detect that and output:</p> <pre><code>[13:32:48] INFO     Activity timestamp is \"2024-05-10T17:17:34\"                              app.py:85\n           INFO     Saving modified data to \"path_to_file_modified.fit\"                      app.py:107\n[13:32:49] WARNING  \u274c Received HTTP conflict (activity already exists) for                  app.py:143\n                    \"path_to_file.fit\"\n</code></pre>"},{"location":"#troubleshooting","title":"Troubleshooting","text":"<p>If you run into problems, please create an issue on the GitHub repo.</p> <p>Note</p> <p>As this is a side-project provided for free (as in speech and beer), support times may vary \ud83d\ude05.</p>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Learn about the development workflow and testing</li> <li>Check the changelog for recent updates</li> <li>View the project on GitHub</li> <li>Install from PyPI</li> </ul>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>The use of any registered or unregistered trademarks owned by third-parties are used only for informational purposes and no endorsement of this software by the owners of such trademarks are implied, explicitly or otherwise. The terms/trademarks Garmin, indieVelo, TrainingPeaks, TrainingPeaks Virtual, Garmin Connect, Stages Cycling, MyWhoosh, Hammerhead Karoo, COROS Dura, Zwift, and any others are used under fair use doctrine solely to facilitate understanding.</p> <p>Likewise, the software is provided \"as is\", without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. In no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software.</p>"},{"location":"#logo","title":"Logo","text":"<p>The application logo was generated primarily using AI tools. If you would like to contribute a better, custom-designed logo, we would welcome pull requests! Please feel free to open a GitHub issue or submit a PR with logo design suggestions.</p>"},{"location":"api/","title":"API Reference","text":"<p>This page documents the public API for Fit File Faker.</p>"},{"location":"api/#main-application-interface-apppy","title":"Main Application interface (<code>app.py</code>)","text":"<p>Main application module for Fit File Faker.</p> <p>This module provides the command-line interface and core application logic for modifying FIT files and uploading them to Garmin Connect. It simulates a Garmin Edge 830 device to enable Training Effect calculations for activities from non-Garmin sources.</p> <p>The module includes:</p> <ul> <li>CLI argument parsing and validation</li> <li>FIT file upload to Garmin Connect with OAuth authentication</li> <li>Batch processing of multiple FIT files</li> <li>Directory monitoring for automatic processing of new files</li> <li>Rich console output with colored logs</li> </ul> <p>Typical usage:</p> <pre><code>$ fit-file-faker -s                    # Initial setup\n$ fit-file-faker activity.fit          # Edit single file\n$ fit-file-faker -u activity.fit       # Edit and upload\n$ fit-file-faker -ua                   # Upload all new files\n$ fit-file-faker -m                    # Monitor directory\n</code></pre>"},{"location":"api/#fit_file_faker.app.NewFileEventHandler","title":"NewFileEventHandler","text":"<pre><code>NewFileEventHandler(dryrun: bool = False)\n</code></pre> <p>               Bases: <code>PatternMatchingEventHandler</code></p> <p>Event handler for monitoring directory changes and processing new FIT files.</p> <p>Extends watchdog's PatternMatchingEventHandler to automatically process and upload new FIT files as they're created in the monitored directory. Includes a 5-second delay to ensure the file is fully written before processing.</p> <p>Attributes:</p> Name Type Description <code>dryrun</code> <p>If <code>True</code>, detects files but doesn't process them. Useful for testing.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Typically used via monitor() function, but can be instantiated directly:\n&gt;&gt;&gt; from watchdog.observers.polling import PollingObserver as Observer\n&gt;&gt;&gt; handler = NewFileEventHandler(dryrun=False)\n&gt;&gt;&gt; observer = Observer()\n&gt;&gt;&gt; observer.schedule(handler, \"/path/to/fitfiles\", recursive=True)\n&gt;&gt;&gt; observer.start()\n</code></pre> <p>Initialize the file event handler.</p> <p>Parameters:</p> Name Type Description Default <code>dryrun</code> <code>bool</code> <p>If <code>True</code>, log file detections but don't process them. Defaults to <code>False</code>.</p> <code>False</code> Source code in <code>fit_file_faker/app.py</code> <pre><code>def __init__(self, dryrun: bool = False):\n    \"\"\"Initialize the file event handler.\n\n    Args:\n        dryrun: If `True`, log file detections but don't process them.\n            Defaults to `False`.\n    \"\"\"\n    _logger.debug(f\"Creating NewFileEventHandler with {dryrun=}\")\n    super().__init__(\n        patterns=[\"*.fit\"], ignore_directories=True, case_sensitive=False\n    )\n    self.dryrun = dryrun\n</code></pre>"},{"location":"api/#fit_file_faker.app.NewFileEventHandler.on_created","title":"on_created","text":"<pre><code>on_created(event: FileCreatedEvent) -&gt; None\n</code></pre> <p>Handle file creation events.</p> <p>Called by watchdog when a new <code>.fit</code> file is created in the monitored directory. Waits 5 seconds to ensure the file is fully written, then processes all new files in the directory via <code>upload_all()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>FileCreatedEvent</code> <p>The file system event containing the path to the new file.</p> required Note <p>The 5-second delay is necessary because TrainingPeaks Virtual may still be writing to the file when the creation event fires. Without this delay, the file might be incomplete or corrupt.</p> Source code in <code>fit_file_faker/app.py</code> <pre><code>def on_created(self, event: FileCreatedEvent) -&gt; None:\n    \"\"\"Handle file creation events.\n\n    Called by watchdog when a new `.fit` file is created in the monitored\n    directory. Waits 5 seconds to ensure the file is fully written, then\n    processes all new files in the directory via\n    [`upload_all()`][fit_file_faker.app.upload_all].\n\n    Args:\n        event: The file system event containing the path to the new file.\n\n    Note:\n        The 5-second delay is necessary because TrainingPeaks Virtual may\n        still be writing to the file when the creation event fires. Without\n        this delay, the file might be incomplete or corrupt.\n    \"\"\"\n    _logger.info(\n        f'New file detected - \"{event.src_path}\"; sleeping for 5 seconds '\n        \"to ensure TPV finishes writing file\"\n    )\n    if not self.dryrun:\n        # Wait for a short time to make sure TPV has finished writing to the file\n        time.sleep(5)\n        # Run the upload all function\n        p = event.src_path\n        if isinstance(p, bytes):\n            p = p.decode()  # pragma: no cover\n        p = cast(str, p)\n        upload_all(Path(p).parent.absolute())\n    else:\n        _logger.warning(\n            \"Found new file, but not processing because dryrun was requested\"\n        )\n</code></pre>"},{"location":"api/#fit_file_faker.app.monitor","title":"monitor","text":"<pre><code>monitor(watch_dir: Path, dryrun: bool = False)\n</code></pre> <p>Monitor a directory for new FIT files and automatically process them.</p> <p>Uses watchdog's PollingObserver to watch for new .fit files in the specified directory. When a new file is detected, waits 5 seconds to ensure it's fully written, then processes and uploads it via <code>upload_all()</code>.</p> <p>The monitor runs until interrupted by Ctrl-C (<code>KeyboardInterrupt</code>).</p> <p>Parameters:</p> Name Type Description Default <code>watch_dir</code> <code>Path</code> <p>Path to the directory to monitor.</p> required <code>dryrun</code> <code>bool</code> <p>If <code>True</code>, detects new files but doesn't process them. Defaults to <code>False</code>.</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Monitor a directory\n&gt;&gt;&gt; monitor(Path(\"/home/user/TPVirtual/abc123/FITFiles\"))\nMonitoring directory: \"/home/user/TPVirtual/abc123/FITFiles\"\n# Press Ctrl-C to stop\n</code></pre> Note <p>Uses <code>PollingObserver</code> for cross-platform compatibility. This may be less efficient than platform-specific observers but works consistently across macOS, Windows, and Linux.</p> Source code in <code>fit_file_faker/app.py</code> <pre><code>def monitor(watch_dir: Path, dryrun: bool = False):\n    \"\"\"Monitor a directory for new FIT files and automatically process them.\n\n    Uses watchdog's PollingObserver to watch for new .fit files in the specified\n    directory. When a new file is detected, waits 5 seconds to ensure it's fully\n    written, then processes and uploads it via [`upload_all()`][fit_file_faker.app.upload_all].\n\n    The monitor runs until interrupted by Ctrl-C (`KeyboardInterrupt`).\n\n    Args:\n        watch_dir: Path to the directory to monitor.\n        dryrun: If `True`, detects new files but doesn't process them.\n            Defaults to `False`.\n\n    Examples:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Monitor a directory\n        &gt;&gt;&gt; monitor(Path(\"/home/user/TPVirtual/abc123/FITFiles\"))\n        Monitoring directory: \"/home/user/TPVirtual/abc123/FITFiles\"\n        # Press Ctrl-C to stop\n\n    Note:\n        Uses `PollingObserver` for cross-platform compatibility. This may be\n        less efficient than platform-specific observers but works consistently\n        across macOS, Windows, and Linux.\n    \"\"\"\n    event_handler = NewFileEventHandler(dryrun=dryrun)\n    observer = Observer()\n    observer.schedule(event_handler, str(watch_dir.absolute()), recursive=True)\n    observer.start()\n    if dryrun:  # pragma: no cover\n        _logger.warning(\"Dryrun was requested, so will not actually take any actions\")\n    _logger.info(f'Monitoring directory: \"{watch_dir.absolute()}\"')\n    try:\n        while observer.is_alive():\n            observer.join(1)\n    except KeyboardInterrupt:\n        _logger.info(\"Received keyboard interrupt, shutting down monitor\")\n    finally:\n        observer.stop()\n        observer.join()\n</code></pre>"},{"location":"api/#fit_file_faker.app.run","title":"run","text":"<pre><code>run()\n</code></pre> <p>Main entry point for the fit-file-faker command-line application.</p> <p>Parses command-line arguments, validates configuration, and executes the appropriate operation (edit, upload, batch upload, or monitor). This function is registered as the console script entry point in pyproject.toml.</p> <p>Command-line options:</p> <pre><code>-s, --initial-setup: Interactive configuration setup\n-u, --upload: Upload file after editing\n-ua, --upload-all: Batch upload all new files\n-p, --preinitialize: Mark all existing files as already uploaded\n-m, --monitor: Monitor directory for new files\n-d, --dryrun: Perform dry run (no file writes or uploads)\n-v, --verbose: Enable verbose debug logging\n</code></pre> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If configuration is invalid, required arguments are missing, or conflicting arguments are provided.</p> <p>Examples:</p> <pre><code># run() is called automatically when running the installed command:\n$ fit-file-faker -s\n$ fit-file-faker -u activity.fit\n$ fit-file-faker -ua\n$ fit-file-faker -m\n</code></pre> Note <p>Requires Python 3.12 or higher. Exits with error if Python version requirement is not met.</p> Source code in <code>fit_file_faker/app.py</code> <pre><code>def run():\n    \"\"\"Main entry point for the fit-file-faker command-line application.\n\n    Parses command-line arguments, validates configuration, and executes the\n    appropriate operation (edit, upload, batch upload, or monitor). This function\n    is registered as the console script entry point in pyproject.toml.\n\n    Command-line options:\n\n        -s, --initial-setup: Interactive configuration setup\n        -u, --upload: Upload file after editing\n        -ua, --upload-all: Batch upload all new files\n        -p, --preinitialize: Mark all existing files as already uploaded\n        -m, --monitor: Monitor directory for new files\n        -d, --dryrun: Perform dry run (no file writes or uploads)\n        -v, --verbose: Enable verbose debug logging\n\n    Raises:\n        SystemExit: If configuration is invalid, required arguments are missing,\n            or conflicting arguments are provided.\n\n    Examples:\n\n        # run() is called automatically when running the installed command:\n        $ fit-file-faker -s\n        $ fit-file-faker -u activity.fit\n        $ fit-file-faker -ua\n        $ fit-file-faker -m\n\n    Note:\n        Requires Python 3.12 or higher. Exits with error if Python version\n        requirement is not met.\n    \"\"\"\n    v = sys.version_info\n    v_str = f\"{v.major}.{v.minor}.{v.micro}\"\n    min_ver = \"3.12.0\"\n    ver = semver.Version.parse(v_str)\n    if not ver &gt;= semver.Version.parse(min_ver):\n        msg = f'This program requires Python \"{min_ver}\" or greater (current version is \"{v_str}\"). Please upgrade your python version.'\n        raise OSError(msg)\n\n    parser = argparse.ArgumentParser(\n        description=\"Tool to add Garmin device information to FIT files and upload them to Garmin Connect. \"\n        \"Currently, only FIT files produced by TrainingPeaks Virtual (https://www.trainingpeaks.com/virtual/) \"\n        \"and Zwift (https://www.zwift.com/) are supported, but it's possible others may work.\"\n    )\n    parser.add_argument(\n        \"input_path\",\n        nargs=\"?\",\n        default=[],\n        help=\"the FIT file or directory to process. This argument can be omitted if the 'fitfiles_path' \"\n        \"config value is set (that directory will be used instead). By default, files will just be edited. \"\n        'Specify the \"-u\" flag to also upload them to Garmin Connect.',\n    )\n    parser.add_argument(\n        \"-s\",\n        \"--initial-setup\",\n        help=\"Use this option to interactively initialize the configuration file (.config.json)\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"-u\",\n        \"--upload\",\n        help=\"upload FIT file (after editing) to Garmin Connect\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"-ua\",\n        \"--upload-all\",\n        action=\"store_true\",\n        help='upload all FIT files in directory (if they are not in \"already processed\" list)',\n    )\n    parser.add_argument(\n        \"-p\",\n        \"--preinitialize\",\n        help=\"preinitialize the list of processed FIT files (mark all existing files in directory as already uploaded)\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"-m\",\n        \"--monitor\",\n        help=\"monitor a directory and upload all newly created FIT files as they are found\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"-d\",\n        \"--dryrun\",\n        help=\"perform a dry run, meaning any files processed will not be saved nor uploaded\",\n        action=\"store_true\",\n    )\n    parser.add_argument(\n        \"-v\", \"--verbose\", help=\"increase verbosity of log output\", action=\"store_true\"\n    )\n    args = parser.parse_args()\n\n    # setup logging before anything else\n    if args.verbose:\n        _logger.setLevel(logging.DEBUG)\n        for logger in [\n            \"urllib3.connectionpool\",\n            \"oauthlib.oauth1.rfc5849\",\n            \"requests_oauthlib.oauth1_auth\",\n            \"asyncio\",\n            \"watchdog.observers.inotify_buffer\",\n        ]:\n            logging.getLogger(logger).setLevel(logging.INFO)\n        _logger.debug(f'Using \"{config_manager.get_config_file_path()}\" as config file')\n    else:\n        _logger.setLevel(logging.INFO)\n        for logger in [\n            \"urllib3.connectionpool\",\n            \"oauthlib.oauth1.rfc5849\",\n            \"requests_oauthlib.oauth1_auth\",\n            \"asyncio\",\n            \"watchdog.observers.inotify_buffer\",\n        ]:\n            logging.getLogger(logger).setLevel(logging.WARNING)\n\n    # if initial_setup, just do config file building\n    if args.initial_setup:\n        config_manager.build_config_file(\n            overwrite_existing_vals=True, rewrite_config=True\n        )\n        _logger.info(\n            f'Config file has been written to \"{config_manager.get_config_file_path()}\", now run one of the other options to '\n            \"start editing/uploading files!\"\n        )\n        sys.exit(0)\n    if not args.input_path and not (\n        args.upload_all or args.monitor or args.preinitialize\n    ):\n        _logger.error(\n            '***************************\\nSpecify either \"--upload-all\", \"--monitor\", \"--preinitialize\", or one input file/directory to use\\n***************************\\n'\n        )\n        parser.print_help()\n        sys.exit(1)\n    if args.monitor and args.upload_all:\n        _logger.error(\n            '***************************\\nCannot use \"--upload-all\" and \"--monitor\" together\\n***************************\\n'\n        )\n        parser.print_help()\n        sys.exit(1)\n\n    # check configuration and prompt for values if needed\n    excluded_keys = [\"fitfiles_path\"] if args.input_path else []\n    if not config_manager.is_valid(excluded_keys=excluded_keys):\n        _logger.warning(\n            \"Config file was not valid, please fill out the following values.\"\n        )\n        config_manager.build_config_file(\n            overwrite_existing_vals=False,\n            rewrite_config=True,\n            excluded_keys=excluded_keys,\n        )\n\n    if args.input_path:\n        p = Path(args.input_path).absolute()\n        _logger.info(f'Using path \"{p}\" from command line input')\n    else:\n        if config_manager.config.fitfiles_path is None:\n            raise EnvironmentError\n        p = Path(config_manager.config.fitfiles_path).absolute()\n        _logger.info(f'Using path \"{p}\" from configuration file')\n\n    if not p.exists():\n        _logger.error(\n            f'Configured/selected path \"{p}\" does not exist, please check your configuration.'\n        )\n        sys.exit(1)\n    if p.is_file():\n        # if p is a single file, do edit and upload\n        _logger.debug(f'\"{p}\" is a single file')\n        output_path = fit_editor.edit_fit(p, dryrun=args.dryrun)\n        if (args.upload or args.upload_all) and output_path:\n            upload(output_path, original_path=p, dryrun=args.dryrun)\n    else:\n        _logger.debug(f'\"{p}\" is a directory')\n        # if p is directory, do other stuff\n        if args.upload_all or args.preinitialize:\n            upload_all(p, args.preinitialize, args.dryrun)\n        elif args.monitor:\n            monitor(p, args.dryrun)\n        else:\n            files_to_edit = list(p.glob(\"*.fit\", case_sensitive=False))\n            _logger.info(f\"Found {len(files_to_edit)} FIT files to edit\")\n            for f in files_to_edit:\n                fit_editor.edit_fit(f, dryrun=args.dryrun)\n</code></pre>"},{"location":"api/#fit_file_faker.app.upload","title":"upload","text":"<pre><code>upload(fn: Path, original_path: Optional[Path] = None, dryrun: bool = False)\n</code></pre> <p>Upload a FIT file to Garmin Connect.</p> <p>Authenticates to Garmin Connect using stored credentials or interactive prompts, then uploads the specified FIT file. Credentials are cached in a platform-specific cache directory for future use.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Path</code> <p>Path to the (modified) FIT file to upload.</p> required <code>original_path</code> <code>Optional[Path]</code> <p>Optional path to the original file for logging purposes. Defaults to <code>None</code>.</p> <code>None</code> <code>dryrun</code> <code>bool</code> <p>If <code>True</code>, authenticates but doesn't actually upload the file. Defaults to <code>False</code>.</p> <code>False</code> <p>Raises:</p> Type Description <code>GarthHTTPError</code> <p>If upload fails with an HTTP error. 409 (conflict/duplicate) errors are caught and logged as warnings, but other HTTP errors are re-raised.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; # Upload a modified file\n&gt;&gt;&gt; upload(Path(\"activity_modified.fit\"))\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Dry run (authenticate but don't upload)\n&gt;&gt;&gt; upload(Path(\"activity_modified.fit\"), dryrun=True)\n</code></pre> Note <p>Garmin Connect credentials are read from the configuration file. If not found there, the user is prompted interactively. Credentials are cached in ~/.cache/FitFileFaker/.garth (location varies by platform).</p> Source code in <code>fit_file_faker/app.py</code> <pre><code>def upload(fn: Path, original_path: Optional[Path] = None, dryrun: bool = False):\n    \"\"\"Upload a FIT file to Garmin Connect.\n\n    Authenticates to Garmin Connect using stored credentials or interactive prompts,\n    then uploads the specified FIT file. Credentials are cached in a platform-specific\n    cache directory for future use.\n\n    Args:\n        fn: Path to the (modified) FIT file to upload.\n        original_path: Optional path to the original file for logging purposes.\n            Defaults to `None`.\n        dryrun: If `True`, authenticates but doesn't actually upload the file.\n            Defaults to `False`.\n\n    Raises:\n        GarthHTTPError: If upload fails with an HTTP error. 409 (conflict/duplicate)\n            errors are caught and logged as warnings, but other HTTP errors are re-raised.\n\n    Examples:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; # Upload a modified file\n        &gt;&gt;&gt; upload(Path(\"activity_modified.fit\"))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Dry run (authenticate but don't upload)\n        &gt;&gt;&gt; upload(Path(\"activity_modified.fit\"), dryrun=True)\n\n    Note:\n        Garmin Connect credentials are read from the configuration file. If not\n        found there, the user is prompted interactively. Credentials are cached\n        in ~/.cache/FitFileFaker/.garth (location varies by platform).\n    \"\"\"\n    # get credentials and login if needed\n    import garth\n    from garth.exc import GarthException, GarthHTTPError\n\n    garth_dir = dirs.user_cache_path / \".garth\"\n    garth_dir.mkdir(exist_ok=True)\n    _logger.debug(f'Using \"{garth_dir}\" for garth credentials')\n\n    try:\n        garth.resume(str(garth_dir.absolute()))\n        garth.client.username\n        _logger.debug(f'Using stored Garmin credentials from \"{garth_dir}\" directory')\n    except (GarthException, FileNotFoundError):\n        # Session is expired. You'll need to log in again\n        _logger.info(\"Authenticating to Garmin Connect\")\n        email = config_manager.config.garmin_username\n        password = config_manager.config.garmin_password\n        if not email:\n            email = questionary.text(\n                'No \"garmin_username\" variable set; Enter email address: '\n            ).ask()\n        _logger.debug(f'Using username \"{email}\"')\n        if not password:\n            password = questionary.password(\n                'No \"garmin_password\" variable set; Enter password: '\n            ).ask()\n            _logger.debug(\"Using password from user input\")\n        else:\n            _logger.debug('Using password stored in \"garmin_password\"')\n        garth.login(email, password)\n        garth.save(str(garth_dir.absolute()))\n\n    with fn.open(\"rb\") as f:\n        try:\n            if not dryrun:\n                _logger.info(f'Uploading \"{fn}\" using garth')\n                garth.client.upload(f)\n                _logger.info(\n                    f':white_check_mark: Successfully uploaded \"{str(original_path)}\"'\n                )\n            else:\n                _logger.info(f'Skipping upload of \"{fn}\" because dryrun was requested')\n        except GarthHTTPError as e:\n            if e.error.response.status_code == 409:\n                _logger.warning(\n                    f':x: Received HTTP conflict (activity already exists) for \"{str(original_path)}\"'\n                )\n            else:\n                raise e\n</code></pre>"},{"location":"api/#fit_file_faker.app.upload_all","title":"upload_all","text":"<pre><code>upload_all(dir: Path, preinitialize: bool = False, dryrun: bool = False)\n</code></pre> <p>Batch process and upload all new FIT files in a directory.</p> <p>Scans the directory for FIT files that haven't been processed yet, edits them to appear as Garmin Edge 830 files, and uploads them to Garmin Connect. Maintains a <code>.uploaded_files.json</code> file to track which files have been processed.</p> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>Path</code> <p>Path to the directory containing FIT files to process.</p> required <code>preinitialize</code> <code>bool</code> <p>If <code>True</code>, marks all existing files as already uploaded without actually processing them. Useful for initializing the tracking file. Defaults to <code>False</code>.</p> <code>False</code> <code>dryrun</code> <code>bool</code> <p>If <code>True</code>, processes files but doesn't upload or update the tracking file. Defaults to <code>False</code>.</p> <code>False</code> Note <p>Files ending in \"_modified.fit\" are automatically excluded to avoid re-processing previously modified files. Temporary files are used for uploads and are automatically deleted afterwards.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Process and upload all new files\n&gt;&gt;&gt; upload_all(Path(\"/home/user/TPVirtual/abc123/FITFiles\"))\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Initialize tracking without processing\n&gt;&gt;&gt; upload_all(Path(\"/path/to/fitfiles\"), preinitialize=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Dry run (no uploads or tracking updates)\n&gt;&gt;&gt; upload_all(Path(\"/path/to/fitfiles\"), dryrun=True)\n</code></pre> Source code in <code>fit_file_faker/app.py</code> <pre><code>def upload_all(dir: Path, preinitialize: bool = False, dryrun: bool = False):\n    \"\"\"Batch process and upload all new FIT files in a directory.\n\n    Scans the directory for FIT files that haven't been processed yet, edits them\n    to appear as Garmin Edge 830 files, and uploads them to Garmin Connect. Maintains\n    a `.uploaded_files.json` file to track which files have been processed.\n\n    Args:\n        dir: Path to the directory containing FIT files to process.\n        preinitialize: If `True`, marks all existing files as already uploaded\n            without actually processing them. Useful for initializing the tracking\n            file. Defaults to `False`.\n        dryrun: If `True`, processes files but doesn't upload or update the tracking\n            file. Defaults to `False`.\n\n    Note:\n        Files ending in \"_modified.fit\" are automatically excluded to avoid\n        re-processing previously modified files. Temporary files are used for\n        uploads and are automatically deleted afterwards.\n\n    Examples:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Process and upload all new files\n        &gt;&gt;&gt; upload_all(Path(\"/home/user/TPVirtual/abc123/FITFiles\"))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Initialize tracking without processing\n        &gt;&gt;&gt; upload_all(Path(\"/path/to/fitfiles\"), preinitialize=True)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Dry run (no uploads or tracking updates)\n        &gt;&gt;&gt; upload_all(Path(\"/path/to/fitfiles\"), dryrun=True)\n    \"\"\"\n    files_uploaded = dir.joinpath(FILES_UPLOADED_NAME)\n    if files_uploaded.exists():\n        # load uploaded file list from disk\n        with files_uploaded.open(\"r\") as f:\n            uploaded_files = json.load(f)\n    else:\n        uploaded_files = []\n        with files_uploaded.open(\"w\") as f:\n            # write blank file\n            json.dump(uploaded_files, f, indent=2)\n    _logger.debug(f\"Found the following already uploaded files: {uploaded_files}\")\n\n    # glob all .fit files in the current directory\n    files = [str(i) for i in dir.glob(\"*.fit\", case_sensitive=False)]\n    # strip any leading/trailing slashes from filenames\n    files = [i.replace(str(dir), \"\").strip(\"/\").strip(\"\\\\\") for i in files]\n    # remove files matching what we may have already processed\n    files = [i for i in files if not i.endswith(\"_modified.fit\")]\n    # remove files found in the \"already uploaded\" list\n    files = [i for i in files if i not in uploaded_files]\n\n    _logger.info(f\"Found {len(files)} files to edit/upload\")\n    _logger.debug(f\"Files to upload: {files}\")\n\n    if not files:\n        return\n\n    for f in files:\n        _logger.info(f'Processing \"{f}\"')  # type: ignore\n\n        if not preinitialize:\n            with NamedTemporaryFile(delete=True, delete_on_close=False) as fp:\n                output = fit_editor.edit_fit(dir.joinpath(f), output=Path(fp.name))\n                if output:\n                    _logger.info(\"Uploading modified file to Garmin Connect\")\n                    upload(output, original_path=Path(f), dryrun=dryrun)\n                    _logger.debug(f'Adding \"{f}\" to \"uploaded_files\"')\n        else:\n            _logger.info(\n                \"Preinitialize was requested, so just marking as uploaded (not actually processing)\"\n            )\n        uploaded_files.append(f)\n\n    if not dryrun:\n        with files_uploaded.open(\"w\") as f:\n            json.dump(uploaded_files, f, indent=2)\n</code></pre>"},{"location":"api/#fit-editor-fit_editorpy","title":"FIT Editor (<code>fit_editor.py</code>)","text":""},{"location":"api/#fit_file_faker.fit_editor.FitEditor","title":"FitEditor","text":"<pre><code>FitEditor()\n</code></pre> <p>Handles FIT file editing and manipulation.</p> <p>This class provides methods to read, modify, and save FIT files from various cycling platforms (TrainingPeaks Virtual, Zwift, COROS, etc.), converting them to appear as if they came from a Garmin Edge 830 device.</p> <p>The editor modifies only device metadata (manufacturer, product IDs) while preserving all activity data including records, laps, and sessions. This enables Garmin Connect's Training Effect calculations for activities from non-Garmin sources.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fit_file_faker.fit_editor import fit_editor\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Edit a single file\n&gt;&gt;&gt; output = fit_editor.edit_fit(Path(\"activity.fit\"))\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Dry run mode (no file written)\n&gt;&gt;&gt; output = fit_editor.edit_fit(Path(\"activity.fit\"), dryrun=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom output location\n&gt;&gt;&gt; output = fit_editor.edit_fit(\n...     Path(\"activity.fit\"),\n...     output=Path(\"modified_activity.fit\")\n... )\n</code></pre> <p>Initialize the FIT editor.</p> <p>Applies a logging filter to suppress verbose fit_tool warnings.</p> Source code in <code>fit_file_faker/fit_editor.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the FIT editor.\n\n    Applies a logging filter to suppress verbose fit_tool warnings.\n    \"\"\"\n    # Apply the log filter to suppress noisy fit_tool warnings\n    logging.getLogger(\"fit_tool\").addFilter(FitFileLogFilter())\n</code></pre>"},{"location":"api/#fit_file_faker.fit_editor.FitEditor.edit_fit","title":"edit_fit","text":"<pre><code>edit_fit(fit_input: Path | FitFile, output: Optional[Path] = None, dryrun: bool = False) -&gt; Path | None\n</code></pre> <p>Edit a FIT file to appear as if it came from a Garmin Edge 830.</p> <p>This is the primary method for converting FIT files from virtual cycling platforms to Garmin-compatible format. It modifies device metadata (manufacturer and product IDs) while preserving all activity data.</p> <p>The method performs the following transformations:</p> <ol> <li>Strips unknown field definitions to prevent corruption</li> <li>Rewrites <code>FileIdMessage</code> with Garmin Edge 830 metadata</li> <li>Adds a <code>FileCreatorMessage</code> with Edge 830 software/hardware versions</li> <li>Modifies <code>DeviceInfoMessage</code> records to match Edge 830</li> <li>Reorders <code>Activity</code> messages to end of file (COROS compatibility)</li> </ol> <p>Parameters:</p> Name Type Description Default <code>fit_input</code> <code>Path | FitFile</code> <p>Either a <code>Path</code> to the input FIT file OR a pre-parsed <code>FitFile</code> object. Using a <code>Path</code> is recommended for most cases.</p> required <code>output</code> <code>Optional[Path]</code> <p>Optional output path. Defaults to {original}_modified.fit when <code>fit_input</code> is a <code>Path</code>. Required if <code>fit_input</code> is a <code>FitFile</code> object.</p> <code>None</code> <code>dryrun</code> <code>bool</code> <p>If <code>True</code>, performs all processing but doesn't write the output file. Useful for validation and testing.</p> <code>False</code> <p>Returns:</p> Type Description <code>Path | None</code> <p>Path to the output file if successful, or <code>None</code> if processing</p> <code>Path | None</code> <p>failed (e.g., invalid FIT file).</p> <p>Raises:</p> Type Description <code>None</code> <p>Errors are logged but not raised. Returns <code>None</code> on failure.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from fit_file_faker.fit_editor import fit_editor\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Basic usage\n&gt;&gt;&gt; output = fit_editor.edit_fit(Path(\"activity.fit\"))\n&gt;&gt;&gt; print(f\"Modified file: {output}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Custom output path\n&gt;&gt;&gt; output = fit_editor.edit_fit(\n...     Path(\"activity.fit\"),\n...     output=Path(\"custom_output.fit\")\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Dry run (no file written)\n&gt;&gt;&gt; output = fit_editor.edit_fit(Path(\"activity.fit\"), dryrun=True)\n</code></pre> Note <p>Only modifies device metadata. All activity data (records, laps, sessions, heart rate, power, etc.) is preserved exactly as-is.</p> Source code in <code>fit_file_faker/fit_editor.py</code> <pre><code>def edit_fit(\n    self,\n    fit_input: Path | FitFile,\n    output: Optional[Path] = None,\n    dryrun: bool = False,\n) -&gt; Path | None:\n    \"\"\"Edit a FIT file to appear as if it came from a Garmin Edge 830.\n\n    This is the primary method for converting FIT files from virtual cycling\n    platforms to Garmin-compatible format. It modifies device metadata\n    (manufacturer and product IDs) while preserving all activity data.\n\n    The method performs the following transformations:\n\n    1. Strips unknown field definitions to prevent corruption\n    2. Rewrites `FileIdMessage` with Garmin Edge 830 metadata\n    3. Adds a `FileCreatorMessage` with Edge 830 software/hardware versions\n    4. Modifies `DeviceInfoMessage` records to match Edge 830\n    5. Reorders `Activity` messages to end of file (COROS compatibility)\n\n    Args:\n        fit_input: Either a `Path` to the input FIT file OR a pre-parsed\n            `FitFile` object. Using a `Path` is recommended for most cases.\n        output: Optional output path. Defaults to {original}_modified.fit\n            when `fit_input` is a `Path`. Required if `fit_input` is a `FitFile`\n            object.\n        dryrun: If `True`, performs all processing but doesn't write the\n            output file. Useful for validation and testing.\n\n    Returns:\n        Path to the output file if successful, or `None` if processing\n        failed (e.g., invalid FIT file).\n\n    Raises:\n        None: Errors are logged but not raised. Returns `None` on failure.\n\n    Examples:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; from fit_file_faker.fit_editor import fit_editor\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Basic usage\n        &gt;&gt;&gt; output = fit_editor.edit_fit(Path(\"activity.fit\"))\n        &gt;&gt;&gt; print(f\"Modified file: {output}\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Custom output path\n        &gt;&gt;&gt; output = fit_editor.edit_fit(\n        ...     Path(\"activity.fit\"),\n        ...     output=Path(\"custom_output.fit\")\n        ... )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Dry run (no file written)\n        &gt;&gt;&gt; output = fit_editor.edit_fit(Path(\"activity.fit\"), dryrun=True)\n\n    Note:\n        Only modifies device metadata. All activity data (records, laps,\n        sessions, heart rate, power, etc.) is preserved exactly as-is.\n    \"\"\"\n    if dryrun:\n        _logger.warning('In \"dryrun\" mode; will not actually write new file.')\n\n    # Handle both Path and FitFile inputs\n    if isinstance(fit_input, Path):\n        fit_path = fit_input\n        _logger.info(f'Processing \"{fit_path}\"')\n\n        try:\n            fit_file = FitFile.from_file(str(fit_path))\n        except Exception:\n            _logger.error(\"File does not appear to be a FIT file, skipping...\")\n            return None\n    elif isinstance(fit_input, FitFile):\n        fit_file = fit_input\n        fit_path = None  # No source path available\n        _logger.info(\"Processing parsed FIT file\")\n    else:\n        _logger.error(f\"Invalid input type: {type(fit_input)}\")\n        return None\n\n    # Strip unknown field definitions to prevent corruption when rewriting\n    self.strip_unknown_fields(fit_file)\n\n    if not output:\n        if fit_path:\n            output = fit_path.parent / f\"{fit_path.stem}_modified.fit\"\n        else:\n            _logger.error(\"Output path required when using parsed FIT file\")\n            return None\n\n    builder = FitFileBuilder(auto_define=True)\n    skipped_device_type_zero = False\n\n    # Collect Activity messages to write at the end (fixes COROS file ordering)\n    activity_messages = []\n\n    # Loop through records, find the ones we need to change, and modify the values\n    for i, record in enumerate(fit_file.records):\n        message = record.message\n\n        # Defer Activity messages until the end to ensure proper ordering\n        if isinstance(message, ActivityMessage):\n            activity_messages.append(message)\n            continue\n\n        # Change file id to indicate file was saved by Edge 830\n        if message.global_id == FileIdMessage.ID:\n            if isinstance(message, DefinitionMessage):\n                # If this is the definition message for the FileIdMessage, skip it\n                # since we're going to write a new one\n                continue\n            if isinstance(message, FileIdMessage):\n                # Rewrite the FileIdMessage and its definition and add to builder\n                def_message, message = self.rewrite_file_id_message(message, i)\n                builder.add(def_message)\n                builder.add(message)\n                # Also add a customized FileCreatorMessage\n                creator_message = FileCreatorMessage()\n                creator_message.software_version = 975\n                creator_message.hardware_version = 255\n                builder.add(DefinitionMessage.from_data_message(creator_message))\n                builder.add(creator_message)\n                continue\n\n        if message.global_id == FileCreatorMessage.ID:\n            # Skip any existing file creator message\n            continue\n\n        # Change device info messages\n        if message.global_id == DeviceInfoMessage.ID:\n            if isinstance(message, DeviceInfoMessage):\n                self.print_message(f\"DeviceInfoMessage Record: {i}\", message)\n                if message.device_type == 0:\n                    _logger.debug(\"    Skipping device_type 0\")\n                    skipped_device_type_zero = True\n                    continue\n\n                # Renumber device_index if we skipped device_type 0\n                if skipped_device_type_zero and message.device_index is not None:\n                    _logger.debug(\n                        f\"    Renumbering device_index from {message.device_index} to {message.device_index - 1}\"\n                    )\n                    message.device_index = message.device_index - 1\n\n                if self._should_modify_device_info(message.manufacturer):\n                    _logger.debug(\"    Modifying values\")\n                    _logger.debug(f\"garmin_product: {message.garmin_product}\")\n                    _logger.debug(f\"product: {message.product}\")\n                    # have not seen this set explicitly in testing, but probable good to set regardless\n                    if message.garmin_product:  # pragma: no cover\n                        message.garmin_product = GarminProduct.EDGE_830.value\n                    if message.product:\n                        message.product = GarminProduct.EDGE_830.value  # type: ignore\n                    if message.manufacturer:\n                        message.manufacturer = Manufacturer.GARMIN.value\n                    message.product_name = \"\"\n                    self.print_message(f\"    New Record: {i}\", message)\n\n        builder.add(message)\n\n    # Add Activity messages at the end to ensure proper FIT file structure\n    if activity_messages:\n        _logger.debug(\n            f\"Adding {len(activity_messages)} Activity message(s) at the end\"\n        )\n        for activity_msg in activity_messages:\n            builder.add(activity_msg)\n\n    modified_file = builder.build()\n\n    if not dryrun:\n        _logger.info(f'Saving modified data to \"{output}\"')\n        modified_file.to_file(str(output))\n    else:\n        _logger.info(\n            f\"Dryrun requested, so not saving data \"\n            f'(would have written to \"{output}\")'\n        )\n\n    return output\n</code></pre>"},{"location":"api/#fit_file_faker.fit_editor.FitEditor.rewrite_file_id_message","title":"rewrite_file_id_message","text":"<pre><code>rewrite_file_id_message(m: FileIdMessage, message_num: int) -&gt; tuple[DefinitionMessage, FileIdMessage]\n</code></pre> <p>Rewrite FileIdMessage to appear as if from Garmin Edge 830.</p> <p>Creates a new FileIdMessage with Garmin Edge 830 manufacturer and product IDs while preserving the original timestamp, type, and serial number. This is the primary transformation that enables Garmin Connect to recognize and process the activity.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>FileIdMessage</code> <p>The original FileIdMessage to rewrite.</p> required <code>message_num</code> <code>int</code> <p>The record number for logging purposes.</p> required <p>Returns:</p> Type Description <code>tuple[DefinitionMessage, FileIdMessage]</code> <p>A tuple containing:</p> <ul> <li><code>DefinitionMessage</code>: Auto-generated definition for the new message.</li> <li><code>FileIdMessage</code>: The rewritten message with Garmin Edge 830 metadata.</li> </ul> Note <p>The product_name field is intentionally not copied as Garmin devices typically don't set this field. Only files from supported manufacturers (<code>DEVELOPMENT</code>, <code>ZWIFT</code>, <code>WAHOO_FITNESS</code>, <code>PEAKSWARE</code>, <code>HAMMERHEAD</code>, <code>COROS</code>, <code>MYWHOOSH</code>) are modified; others are returned unchanged.</p> Source code in <code>fit_file_faker/fit_editor.py</code> <pre><code>def rewrite_file_id_message(\n    self,\n    m: FileIdMessage,\n    message_num: int,\n) -&gt; tuple[DefinitionMessage, FileIdMessage]:\n    \"\"\"Rewrite FileIdMessage to appear as if from Garmin Edge 830.\n\n    Creates a new FileIdMessage with Garmin Edge 830 manufacturer and\n    product IDs while preserving the original timestamp, type, and serial\n    number. This is the primary transformation that enables Garmin Connect\n    to recognize and process the activity.\n\n    Args:\n        m: The original FileIdMessage to rewrite.\n        message_num: The record number for logging purposes.\n\n    Returns:\n        A tuple containing:\n\n            - `DefinitionMessage`: Auto-generated definition for the new message.\n            - `FileIdMessage`: The rewritten message with Garmin Edge 830 metadata.\n\n    Note:\n        The product_name field is intentionally not copied as Garmin devices\n        typically don't set this field. Only files from supported manufacturers\n        (`DEVELOPMENT`, `ZWIFT`, `WAHOO_FITNESS`, `PEAKSWARE`, `HAMMERHEAD`, `COROS`,\n        `MYWHOOSH`) are modified; others are returned unchanged.\n    \"\"\"\n    dt = datetime.fromtimestamp(m.time_created / 1000.0)  # type: ignore\n    _logger.info(f'Activity timestamp is \"{dt.isoformat()}\"')\n    self.print_message(f\"FileIdMessage Record: {message_num}\", m)\n\n    new_m = FileIdMessage()\n    new_m.time_created = (\n        m.time_created if m.time_created else int(datetime.now().timestamp() * 1000)\n    )\n    if m.type:\n        new_m.type = m.type\n    if m.serial_number is not None:\n        new_m.serial_number = m.serial_number\n    if m.product_name:\n        # garmin does not appear to define product_name, so don't copy it over\n        pass\n\n    if self._should_modify_manufacturer(m.manufacturer):\n        new_m.manufacturer = Manufacturer.GARMIN.value\n        new_m.product = GarminProduct.EDGE_830.value\n        _logger.debug(\"    Modifying values\")\n        self.print_message(f\"    New Record: {message_num}\", new_m)\n\n    return (DefinitionMessage.from_data_message(new_m), new_m)\n</code></pre>"},{"location":"api/#fit_file_faker.fit_editor.FitEditor.get_date_from_fit","title":"get_date_from_fit","text":"<pre><code>get_date_from_fit(fit_path: Path) -&gt; Optional[datetime]\n</code></pre> <p>Extract the creation date from a FIT file.</p> <p>Reads the FIT file and extracts the timestamp from the <code>FileIdMessage</code>, which indicates when the activity was recorded.</p> <p>Parameters:</p> Name Type Description Default <code>fit_path</code> <code>Path</code> <p><code>Path</code> to the FIT file to read.</p> required <p>Returns:</p> Type Description <code>Optional[datetime]</code> <p>The activity creation datetime, or <code>None</code> if no <code>FileIdMessage</code> with</p> <code>Optional[datetime]</code> <p>a valid timestamp was found.</p> Note <p>The timestamp in FIT files is stored in milliseconds since the FIT epoch, which is converted to a standard Python datetime object.</p> Source code in <code>fit_file_faker/fit_editor.py</code> <pre><code>def get_date_from_fit(self, fit_path: Path) -&gt; Optional[datetime]:\n    \"\"\"Extract the creation date from a FIT file.\n\n    Reads the FIT file and extracts the timestamp from the `FileIdMessage`,\n    which indicates when the activity was recorded.\n\n    Args:\n        fit_path: `Path` to the FIT file to read.\n\n    Returns:\n        The activity creation datetime, or `None` if no `FileIdMessage` with\n        a valid timestamp was found.\n\n    Note:\n        The timestamp in FIT files is stored in milliseconds since the\n        FIT epoch, which is converted to a standard Python datetime object.\n    \"\"\"\n    fit_file = FitFile.from_file(str(fit_path))\n    res = None\n    for i, record in enumerate(fit_file.records):\n        message = record.message\n        if message.global_id == FileIdMessage.ID:\n            if isinstance(message, FileIdMessage):\n                res = datetime.fromtimestamp(message.time_created / 1000.0)  # type: ignore\n                break\n    return res\n</code></pre>"},{"location":"api/#fit_file_faker.fit_editor.FitEditor.strip_unknown_fields","title":"strip_unknown_fields","text":"<pre><code>strip_unknown_fields(fit_file: FitFile) -&gt; None\n</code></pre> <p>Force regeneration of definition messages for messages with unknown fields.</p> <p>This fixes a bug where <code>fit_tool</code> skips unknown fields (like Zwift's field 193) during reading but keeps them in the definition, causing a mismatch when writing. Without this fix, the file would be corrupted when written back out.</p> <p>The method sets <code>definition_message</code> to <code>None</code> for affected messages, forcing <code>FitFileBuilder</code> to regenerate clean definitions based only on fields that actually exist in the message.</p> <p>Parameters:</p> Name Type Description Default <code>fit_file</code> <code>FitFile</code> <p>The parsed FIT file to process. Messages are modified in place.</p> required Note <p>This is called automatically by <code>edit_fit()</code> before processing any FIT file. It's essential for handling files from platforms like Zwift that use custom/unknown field IDs.</p> Source code in <code>fit_file_faker/fit_editor.py</code> <pre><code>def strip_unknown_fields(self, fit_file: FitFile) -&gt; None:\n    \"\"\"Force regeneration of definition messages for messages with unknown fields.\n\n    This fixes a bug where `fit_tool` skips unknown fields (like Zwift's field 193)\n    during reading but keeps them in the definition, causing a mismatch when writing.\n    Without this fix, the file would be corrupted when written back out.\n\n    The method sets `definition_message` to `None` for affected messages, forcing\n    `FitFileBuilder` to regenerate clean definitions based only on fields that\n    actually exist in the message.\n\n    Args:\n        fit_file: The parsed FIT file to process. Messages are modified in place.\n\n    Note:\n        This is called automatically by\n        [`edit_fit()`][fit_file_faker.fit_editor.FitEditor.edit_fit] before\n        processing any FIT file. It's essential for handling files from platforms\n        like Zwift that use custom/unknown field IDs.\n    \"\"\"\n    for record in fit_file.records:\n        message = record.message\n        if (\n            not hasattr(message, \"definition_message\")\n            or message.definition_message is None\n        ):\n            continue\n        if not hasattr(message, \"fields\"):  # pragma: no cover\n            continue\n\n        # Get the set of field IDs that actually exist in the message\n        existing_field_ids = {\n            field.field_id for field in message.fields if field.is_valid()\n        }\n\n        # Check if definition has fields that don't exist in the message\n        definition_field_ids = {\n            fd.field_id for fd in message.definition_message.field_definitions\n        }\n\n        unknown_fields = definition_field_ids - existing_field_ids\n        if unknown_fields:\n            _logger.debug(\n                f\"Clearing definition for {message.name} (global_id={message.global_id}) \"\n                f\"to force regeneration (had {len(unknown_fields)} unknown field(s))\"\n            )\n            # Set to None to force FitFileBuilder to regenerate it\n            message.definition_message = None\n</code></pre>"},{"location":"api/#fit_file_faker.fit_editor.FitEditor._should_modify_manufacturer","title":"_should_modify_manufacturer","text":"<pre><code>_should_modify_manufacturer(manufacturer: int | None) -&gt; bool\n</code></pre> <p>Check if manufacturer should be modified to Garmin.</p> <p>Determines whether a FIT file's manufacturer should be changed to Garmin based on whether it's from a supported virtual cycling platform.</p> <p>Parameters:</p> Name Type Description Default <code>manufacturer</code> <code>int | None</code> <p>The manufacturer code from the FIT file, or <code>None</code>.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the manufacturer is from a supported platform and should</p> <code>bool</code> <p>be modified, False otherwise.</p> Note <p>Supported manufacturers include: <code>DEVELOPMENT</code> (TrainingPeaks Virtual), <code>ZWIFT</code>, <code>WAHOO_FITNESS</code>, <code>PEAKSWARE</code>, <code>HAMMERHEAD</code>, <code>COROS</code>, and <code>MYWHOOSH</code> (<code>331</code>).</p> Source code in <code>fit_file_faker/fit_editor.py</code> <pre><code>def _should_modify_manufacturer(self, manufacturer: int | None) -&gt; bool:\n    \"\"\"Check if manufacturer should be modified to Garmin.\n\n    Determines whether a FIT file's manufacturer should be changed to\n    Garmin based on whether it's from a supported virtual cycling platform.\n\n    Args:\n        manufacturer: The manufacturer code from the FIT file, or `None`.\n\n    Returns:\n        True if the manufacturer is from a supported platform and should\n        be modified, False otherwise.\n\n    Note:\n        Supported manufacturers include: `DEVELOPMENT` (TrainingPeaks Virtual),\n        `ZWIFT`, `WAHOO_FITNESS`, `PEAKSWARE`, `HAMMERHEAD`, `COROS`, and\n        `MYWHOOSH` (`331`).\n    \"\"\"\n    if manufacturer is None:\n        return False\n    return manufacturer in [\n        Manufacturer.DEVELOPMENT.value,\n        Manufacturer.ZWIFT.value,\n        Manufacturer.WAHOO_FITNESS.value,\n        Manufacturer.PEAKSWARE.value,\n        Manufacturer.HAMMERHEAD.value,\n        Manufacturer.COROS.value,\n        331,  # MYWHOOSH is unknown to fit_tools\n    ]\n</code></pre>"},{"location":"api/#fit_file_faker.fit_editor.FitEditor._should_modify_device_info","title":"_should_modify_device_info","text":"<pre><code>_should_modify_device_info(manufacturer: int | None) -&gt; bool\n</code></pre> <p>Check if device info should be modified to Garmin Edge 830.</p> <p>Similar to _should_modify_manufacturer but also includes blank/unknown manufacturers (code 0) for <code>DeviceInfoMessage</code> records.</p> <p>Parameters:</p> Name Type Description Default <code>manufacturer</code> <code>int | None</code> <p>The manufacturer code from the <code>DeviceInfoMessage</code>, or <code>None</code>.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the device info should be modified to Garmin Edge 830,</p> <code>bool</code> <p>False otherwise.</p> Note <p>This includes all manufacturers from <code>_should_modify_manufacturer()</code> plus manufacturer code 0 (blank/unknown).</p> Source code in <code>fit_file_faker/fit_editor.py</code> <pre><code>def _should_modify_device_info(self, manufacturer: int | None) -&gt; bool:\n    \"\"\"Check if device info should be modified to Garmin Edge 830.\n\n    Similar to _should_modify_manufacturer but also includes blank/unknown\n    manufacturers (code 0) for `DeviceInfoMessage` records.\n\n    Args:\n        manufacturer: The manufacturer code from the `DeviceInfoMessage`, or `None`.\n\n    Returns:\n        True if the device info should be modified to Garmin Edge 830,\n        False otherwise.\n\n    Note:\n        This includes all manufacturers from\n        [`_should_modify_manufacturer()`][fit_file_faker.fit_editor.FitEditor._should_modify_manufacturer]\n        plus manufacturer code 0 (blank/unknown).\n    \"\"\"\n    if manufacturer is None:\n        return False\n    return manufacturer in [\n        Manufacturer.DEVELOPMENT.value,\n        0,  # Blank/unknown manufacturer\n        Manufacturer.WAHOO_FITNESS.value,\n        Manufacturer.ZWIFT.value,\n        Manufacturer.PEAKSWARE.value,\n        Manufacturer.HAMMERHEAD.value,\n        Manufacturer.COROS.value,\n        331,  # MYWHOOSH is unknown to fit_tools\n    ]\n</code></pre>"},{"location":"api/#configuration-configpy","title":"Configuration (<code>config.py</code>)","text":"<p>Configuration management for Fit File Faker.</p> <p>This module handles all configuration file operations including creation, validation, loading, and saving. Configuration is stored in a platform-specific user configuration directory using platformdirs.</p> <p>The configuration includes Garmin Connect credentials and the path to the directory containing FIT files to process. For TrainingPeaks Virtual users, the FIT files directory is auto-detected on macOS and Windows.</p> <p>Typical usage example:</p> <pre><code>from fit_file_faker.config import config_manager\n\n# Check if config is valid\nif not config_manager.is_valid():\n    config_manager.build_config_file()\n\n# Access configuration values\nusername = config_manager.config.garmin_username\nfit_path = config_manager.config.fitfiles_path\n</code></pre>"},{"location":"api/#fit_file_faker.config.Config","title":"Config  <code>dataclass</code>","text":"<pre><code>Config(garmin_username: str | None = None, garmin_password: str | None = None, fitfiles_path: Path | None = None)\n</code></pre> <p>Configuration data class for Fit File Faker.</p> <p>Stores all configuration values including Garmin Connect credentials and the path to FIT files directory. All fields are optional to allow incremental configuration building.</p> <p>Attributes:</p> Name Type Description <code>garmin_username</code> <code>str | None</code> <p>Garmin Connect account email address.</p> <code>garmin_password</code> <code>str | None</code> <p>Garmin Connect account password.</p> <code>fitfiles_path</code> <code>Path | None</code> <p>Path to directory containing FIT files to process. For TrainingPeaks Virtual, this typically points to the user's FITFiles directory within their TPVirtual folder.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; config = Config(\n...     garmin_username=\"user@example.com\",\n...     garmin_password=\"secret\",\n...     fitfiles_path=Path(\"/home/user/TPVirtual/abc123/FITFiles\")\n... )\n</code></pre>"},{"location":"api/#fit_file_faker.config.ConfigManager","title":"ConfigManager","text":"<pre><code>ConfigManager()\n</code></pre> <p>Manages configuration file operations and validation.</p> <p>Handles loading, saving, and validating configuration stored in a platform-specific user configuration directory. Provides interactive configuration building for missing or invalid values.</p> <p>The configuration file is stored as <code>.config.json</code> in the user's config directory (location varies by platform).</p> <p>Attributes:</p> Name Type Description <code>config_file</code> <p>Path to the JSON configuration file.</p> <code>config_keys</code> <p>List of required configuration keys.</p> <code>config</code> <p>Current Config object loaded from file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from fit_file_faker.config import config_manager\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Check if config is valid\n&gt;&gt;&gt; if not config_manager.is_valid():\n...     print(f\"Config file: {config_manager.get_config_file_path()}\")\n...     config_manager.build_config_file()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Access config values\n&gt;&gt;&gt; username = config_manager.config.garmin_username\n</code></pre> <p>Initialize the configuration manager.</p> <p>Creates the config file if it doesn't exist and loads existing configuration or creates a new empty Config object.</p> Source code in <code>fit_file_faker/config.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the configuration manager.\n\n    Creates the config file if it doesn't exist and loads existing\n    configuration or creates a new empty Config object.\n    \"\"\"\n    self.config_file = dirs.user_config_path / \".config.json\"\n    self.config_keys = [\"garmin_username\", \"garmin_password\", \"fitfiles_path\"]\n    self.config = self._load_config()\n</code></pre>"},{"location":"api/#fit_file_faker.config.ConfigManager._load_config","title":"_load_config","text":"<pre><code>_load_config() -&gt; Config\n</code></pre> <p>Load configuration from file or create new Config if file doesn't exist.</p> <p>Returns:</p> Type Description <code>Config</code> <p>Loaded Config object if file exists and contains valid JSON,</p> <code>Config</code> <p>otherwise a new empty Config object.</p> Note <p>Creates an empty config file if one doesn't exist.</p> Source code in <code>fit_file_faker/config.py</code> <pre><code>def _load_config(self) -&gt; Config:\n    \"\"\"Load configuration from file or create new Config if file doesn't exist.\n\n    Returns:\n        Loaded Config object if file exists and contains valid JSON,\n        otherwise a new empty Config object.\n\n    Note:\n        Creates an empty config file if one doesn't exist.\n    \"\"\"\n    self.config_file.touch(exist_ok=True)\n\n    with self.config_file.open(\"r\") as f:\n        if self.config_file.stat().st_size == 0:\n            return Config()\n        else:\n            return Config(**json.load(f))\n</code></pre>"},{"location":"api/#fit_file_faker.config.ConfigManager.build_config_file","title":"build_config_file","text":"<pre><code>build_config_file(overwrite_existing_vals: bool = False, rewrite_config: bool = True, excluded_keys: list[str] | None = None) -&gt; None\n</code></pre> <p>Interactively build configuration file.</p> <p>Prompts the user for missing or invalid configuration values using questionary for an interactive CLI experience. Passwords are masked during input, and the FIT files path is auto-detected for TrainingPeaks Virtual users when possible.</p> <p>Parameters:</p> Name Type Description Default <code>overwrite_existing_vals</code> <code>bool</code> <p>If <code>True</code>, prompts for all values even if they already exist. If <code>False</code>, only prompts for missing values. Defaults to <code>False</code>.</p> <code>False</code> <code>rewrite_config</code> <code>bool</code> <p>If <code>True</code>, saves the configuration to disk after building. If <code>False</code>, only updates the in-memory config object. Defaults to <code>True</code>.</p> <code>True</code> <code>excluded_keys</code> <code>list[str] | None</code> <p>Optional list of keys to skip during interactive building. Useful for partial configuration.</p> <code>None</code> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If user presses Ctrl-C to cancel configuration.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Interactive setup for missing values only\n&gt;&gt;&gt; config_manager.build_config_file()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Rebuild entire configuration\n&gt;&gt;&gt; config_manager.build_config_file(overwrite_existing_vals=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Update only credentials (skip fitfiles_path)\n&gt;&gt;&gt; config_manager.build_config_file(\n...     excluded_keys=[\"fitfiles_path\"]\n... )\n</code></pre> Note <p>Passwords are masked in both user input and log output for security. The final configuration is logged with passwords hidden.</p> Source code in <code>fit_file_faker/config.py</code> <pre><code>def build_config_file(\n    self,\n    overwrite_existing_vals: bool = False,\n    rewrite_config: bool = True,\n    excluded_keys: list[str] | None = None,\n) -&gt; None:\n    \"\"\"Interactively build configuration file.\n\n    Prompts the user for missing or invalid configuration values using\n    questionary for an interactive CLI experience. Passwords are masked\n    during input, and the FIT files path is auto-detected for TrainingPeaks\n    Virtual users when possible.\n\n    Args:\n        overwrite_existing_vals: If `True`, prompts for all values even if\n            they already exist. If `False`, only prompts for missing values.\n            Defaults to `False`.\n        rewrite_config: If `True`, saves the configuration to disk after\n            building. If `False`, only updates the in-memory config object.\n            Defaults to `True`.\n        excluded_keys: Optional list of keys to skip during interactive\n            building. Useful for partial configuration.\n\n    Raises:\n        SystemExit: If user presses Ctrl-C to cancel configuration.\n\n    Examples:\n        &gt;&gt;&gt; # Interactive setup for missing values only\n        &gt;&gt;&gt; config_manager.build_config_file()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Rebuild entire configuration\n        &gt;&gt;&gt; config_manager.build_config_file(overwrite_existing_vals=True)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Update only credentials (skip fitfiles_path)\n        &gt;&gt;&gt; config_manager.build_config_file(\n        ...     excluded_keys=[\"fitfiles_path\"]\n        ... )\n\n    Note:\n        Passwords are masked in both user input and log output for security.\n        The final configuration is logged with passwords hidden.\n    \"\"\"\n    if excluded_keys is None:\n        excluded_keys = []\n\n    for k in self.config_keys:\n        if (\n            getattr(self.config, k) is None or overwrite_existing_vals\n        ) and k not in excluded_keys:\n            valid_input = False\n            while not valid_input:\n                try:\n                    if (\n                        not hasattr(self.config, k)\n                        or getattr(self.config, k) is None\n                    ):\n                        _logger.warning(f'Required value \"{k}\" not found in config')\n                    msg = f'Enter value to use for \"{k}\"'\n\n                    if hasattr(self.config, k) and getattr(self.config, k):\n                        msg += f'\\nor press enter to use existing value of \"{getattr(self.config, k)}\"'\n                        if k == \"garmin_password\":\n                            msg = msg.replace(\n                                getattr(self.config, k), \"&lt;**hidden**&gt;\"\n                            )\n\n                    if k != \"fitfiles_path\":\n                        if \"password\" in k:\n                            val = questionary.password(msg).unsafe_ask()\n                        else:\n                            val = questionary.text(msg).unsafe_ask()\n                    else:\n                        val = str(\n                            get_fitfiles_path(\n                                Path(self.config.fitfiles_path).parent.parent\n                                if self.config.fitfiles_path\n                                else None\n                            )\n                        )\n\n                    if val:\n                        valid_input = True\n                        setattr(self.config, k, val)\n                    elif hasattr(self.config, k) and getattr(self.config, k):\n                        valid_input = True\n                        val = getattr(self.config, k)\n                    else:\n                        _logger.warning(\n                            \"Entered input was not valid, please try again (or press Ctrl-C to cancel)\"\n                        )\n                except KeyboardInterrupt:\n                    _logger.error(\"User canceled input; exiting!\")\n                    sys.exit(1)\n\n    if rewrite_config:\n        self.save_config()\n\n    config_content = json.dumps(asdict(self.config), indent=2, cls=PathEncoder)\n    if (\n        hasattr(self.config, \"garmin_password\")\n        and getattr(self.config, \"garmin_password\") is not None\n    ):\n        config_content = config_content.replace(\n            cast(str, self.config.garmin_password), \"&lt;**hidden**&gt;\"\n        )\n    _logger.info(f\"Config file is now:\\n{config_content}\")\n</code></pre>"},{"location":"api/#fit_file_faker.config.ConfigManager.get_config_file_path","title":"get_config_file_path","text":"<pre><code>get_config_file_path() -&gt; Path\n</code></pre> <p>Get the path to the configuration file.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the .config.json file in the platform-specific user</p> <code>Path</code> <p>configuration directory.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; path = config_manager.get_config_file_path()\n&gt;&gt;&gt; print(f\"Config file: {path}\")\nConfig file: /home/user/.config/FitFileFaker/.config.json\n</code></pre> Source code in <code>fit_file_faker/config.py</code> <pre><code>def get_config_file_path(self) -&gt; Path:\n    \"\"\"Get the path to the configuration file.\n\n    Returns:\n        Path to the .config.json file in the platform-specific user\n        configuration directory.\n\n    Examples:\n        &gt;&gt;&gt; path = config_manager.get_config_file_path()\n        &gt;&gt;&gt; print(f\"Config file: {path}\")\n        Config file: /home/user/.config/FitFileFaker/.config.json\n    \"\"\"\n    return self.config_file\n</code></pre>"},{"location":"api/#fit_file_faker.config.ConfigManager.is_valid","title":"is_valid","text":"<pre><code>is_valid(excluded_keys: list[str] | None = None) -&gt; bool\n</code></pre> <p>Check if configuration is valid (all required keys have values).</p> <p>Parameters:</p> Name Type Description Default <code>excluded_keys</code> <code>list[str] | None</code> <p>Optional list of keys to exclude from validation. Useful when certain config values aren't needed for specific operations (e.g., fitfiles_path when path is provided via CLI).</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if all required (non-excluded) keys have non-None values,</p> <code>bool</code> <p>False otherwise. Logs missing keys as errors.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Check all keys\n&gt;&gt;&gt; if not config_manager.is_valid():\n...     print(\"Configuration incomplete\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Exclude fitfiles_path from validation\n&gt;&gt;&gt; if not config_manager.is_valid(excluded_keys=[\"fitfiles_path\"]):\n...     print(\"Missing Garmin credentials\")\n</code></pre> Source code in <code>fit_file_faker/config.py</code> <pre><code>def is_valid(self, excluded_keys: list[str] | None = None) -&gt; bool:\n    \"\"\"Check if configuration is valid (all required keys have values).\n\n    Args:\n        excluded_keys: Optional list of keys to exclude from validation.\n            Useful when certain config values aren't needed for specific\n            operations (e.g., fitfiles_path when path is provided via CLI).\n\n    Returns:\n        True if all required (non-excluded) keys have non-None values,\n        False otherwise. Logs missing keys as errors.\n\n    Examples:\n        &gt;&gt;&gt; # Check all keys\n        &gt;&gt;&gt; if not config_manager.is_valid():\n        ...     print(\"Configuration incomplete\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Exclude fitfiles_path from validation\n        &gt;&gt;&gt; if not config_manager.is_valid(excluded_keys=[\"fitfiles_path\"]):\n        ...     print(\"Missing Garmin credentials\")\n    \"\"\"\n    if excluded_keys is None:\n        excluded_keys = []\n\n    missing_vals = []\n    for k in self.config_keys:\n        if (\n            not hasattr(self.config, k) or getattr(self.config, k) is None\n        ) and k not in excluded_keys:\n            missing_vals.append(k)\n\n    if missing_vals:\n        _logger.error(\n            f\"The following configuration values are missing: {missing_vals}\"\n        )\n        return False\n    return True\n</code></pre>"},{"location":"api/#fit_file_faker.config.ConfigManager.save_config","title":"save_config","text":"<pre><code>save_config() -&gt; None\n</code></pre> <p>Save current configuration to file.</p> <p>Serializes the current Config object to JSON and writes it to the config file with 2-space indentation. Path objects are automatically converted to strings via PathEncoder.</p> Source code in <code>fit_file_faker/config.py</code> <pre><code>def save_config(self) -&gt; None:\n    \"\"\"Save current configuration to file.\n\n    Serializes the current Config object to JSON and writes it to the\n    config file with 2-space indentation. Path objects are automatically\n    converted to strings via PathEncoder.\n    \"\"\"\n    with self.config_file.open(\"w\") as f:\n        json.dump(asdict(self.config), f, indent=2, cls=PathEncoder)\n</code></pre>"},{"location":"api/#fit_file_faker.config.PathEncoder","title":"PathEncoder","text":"<p>               Bases: <code>JSONEncoder</code></p> <p>JSON encoder that handles <code>pathlib.Path</code> objects.</p> <p>Extends <code>json.JSONEncoder</code> to automatically convert Path objects to strings when serializing configuration to JSON format.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import json\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; data = {\"path\": Path(\"/home/user\")}\n&gt;&gt;&gt; json.dumps(data, cls=PathEncoder)\n'{\"path\": \"/home/user\"}'\n</code></pre>"},{"location":"api/#fit_file_faker.config.get_fitfiles_path","title":"get_fitfiles_path","text":"<pre><code>get_fitfiles_path(existing_path: Path | None) -&gt; Path\n</code></pre> <p>Auto-find the FITFiles folder inside a TrainingPeaks Virtual directory.</p> <p>Attempts to automatically locate the user's TrainingPeaks Virtual FITFiles directory. On macOS/Windows, the TPVirtual data directory is auto-detected. On Linux, the user is prompted to provide the path.</p> <p>If multiple user directories exist, the user is prompted to select one.</p> <p>Parameters:</p> Name Type Description Default <code>existing_path</code> <code>Path | None</code> <p>Optional path to use as default. If provided, this path's <code>parent.parent</code> is used as the TPVirtual base directory.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the FITFiles directory (e.g., <code>~/TPVirtual/abc123def/FITFiles</code>).</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If no TP Virtual user folder is found, the user rejects the auto-detected folder, or the user cancels the selection.</p> Note <p>The TPVirtual folder location can be overridden using the <code>TPV_DATA_PATH</code> environment variable. User directories are identified by 16-character hexadecimal folder names.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Auto-detect FITFiles path\n&gt;&gt;&gt; path = get_fitfiles_path(None)\n&gt;&gt;&gt; print(path)\n/Users/me/TPVirtual/a1b2c3d4e5f6g7h8/FITFiles\n</code></pre> Source code in <code>fit_file_faker/config.py</code> <pre><code>def get_fitfiles_path(existing_path: Path | None) -&gt; Path:\n    \"\"\"Auto-find the FITFiles folder inside a TrainingPeaks Virtual directory.\n\n    Attempts to automatically locate the user's TrainingPeaks Virtual FITFiles\n    directory. On macOS/Windows, the TPVirtual data directory is auto-detected.\n    On Linux, the user is prompted to provide the path.\n\n    If multiple user directories exist, the user is prompted to select one.\n\n    Args:\n        existing_path: Optional path to use as default. If provided, this path's\n            `parent.parent` is used as the TPVirtual base directory.\n\n    Returns:\n        Path to the FITFiles directory (e.g., `~/TPVirtual/abc123def/FITFiles`).\n\n    Raises:\n        SystemExit: If no TP Virtual user folder is found, the user rejects\n            the auto-detected folder, or the user cancels the selection.\n\n    Note:\n        The TPVirtual folder location can be overridden using the\n        `TPV_DATA_PATH` environment variable. User directories are identified\n        by 16-character hexadecimal folder names.\n\n    Examples:\n        &gt;&gt;&gt; # Auto-detect FITFiles path\n        &gt;&gt;&gt; path = get_fitfiles_path(None)\n        &gt;&gt;&gt; print(path)\n        /Users/me/TPVirtual/a1b2c3d4e5f6g7h8/FITFiles\n    \"\"\"\n    _logger.info(\"Getting FITFiles folder\")\n\n    TPVPath = get_tpv_folder(existing_path)\n    res = [f for f in os.listdir(TPVPath) if re.search(r\"\\A(\\w){16}\\Z\", f)]\n    if len(res) == 0:\n        _logger.error(\n            'Cannot find a TP Virtual User folder in \"%s\", please check if you have previously logged into TP Virtual',\n            TPVPath,\n        )\n        sys.exit(1)\n    elif len(res) == 1:\n        title = f'Found TP Virtual User directory at \"{Path(TPVPath) / res[0]}\", is this correct? '\n        option = questionary.select(title, choices=[\"yes\", \"no\"]).ask()\n        if option == \"no\":\n            # Get config manager instance to access config file path\n            config_manager = ConfigManager()\n            _logger.error(\n                'Failed to find correct TP Virtual User folder please manually configure \"fitfiles_path\" in config file: %s',\n                config_manager.get_config_file_path().absolute(),\n            )\n            sys.exit(1)\n        else:\n            option = res[0]\n    else:\n        title = \"Found multiple TP Virtual User directories, please select the directory for your user: \"\n        option = questionary.select(title, choices=res).ask()\n    TPV_data_path = Path(TPVPath) / option\n    _logger.info(\n        f'Found TP Virtual User directory: \"{str(TPV_data_path.absolute())}\", '\n        'setting \"fitfiles_path\" in config file'\n    )\n    return TPV_data_path / \"FITFiles\"\n</code></pre>"},{"location":"api/#fit_file_faker.config.get_tpv_folder","title":"get_tpv_folder","text":"<pre><code>get_tpv_folder(default_path: Path | None) -&gt; Path\n</code></pre> <p>Get the TrainingPeaks Virtual base folder path.</p> <p>Auto-detects the TPVirtual directory based on platform, or prompts the user to provide it if auto-detection is not available.</p> <p>Platform-specific default locations:</p> <ul> <li>macOS: <code>~/TPVirtual</code></li> <li>Windows: <code>~/Documents/TPVirtual</code></li> <li>Linux: User is prompted (no auto-detection)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>default_path</code> <code>Path | None</code> <p>Optional default path to show in the prompt for Linux users.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the <code>TPVirtual</code> base directory (not the <code>FITFiles</code> subdirectory).</p> Note <p>The auto-detected path can be overridden by setting the <code>TPV_DATA_PATH</code> environment variable.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # macOS\n&gt;&gt;&gt; path = get_tpv_folder(None)\n&gt;&gt;&gt; print(path)\n/Users/me/TPVirtual\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Linux (prompts user)\n&gt;&gt;&gt; path = get_tpv_folder(Path(\"/home/me/custom/path\"))\nPlease enter your TrainingPeaks Virtual data folder: /home/me/TPVirtual\n</code></pre> Source code in <code>fit_file_faker/config.py</code> <pre><code>def get_tpv_folder(default_path: Path | None) -&gt; Path:\n    \"\"\"Get the TrainingPeaks Virtual base folder path.\n\n    Auto-detects the TPVirtual directory based on platform, or prompts the\n    user to provide it if auto-detection is not available.\n\n    Platform-specific default locations:\n\n    - macOS: `~/TPVirtual`\n    - Windows: `~/Documents/TPVirtual`\n    - Linux: User is prompted (no auto-detection)\n\n    Args:\n        default_path: Optional default path to show in the prompt for Linux users.\n\n    Returns:\n        Path to the `TPVirtual` base directory (not the `FITFiles` subdirectory).\n\n    Note:\n        The auto-detected path can be overridden by setting the `TPV_DATA_PATH`\n        environment variable.\n\n    Examples:\n        &gt;&gt;&gt; # macOS\n        &gt;&gt;&gt; path = get_tpv_folder(None)\n        &gt;&gt;&gt; print(path)\n        /Users/me/TPVirtual\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Linux (prompts user)\n        &gt;&gt;&gt; path = get_tpv_folder(Path(\"/home/me/custom/path\"))\n        Please enter your TrainingPeaks Virtual data folder: /home/me/TPVirtual\n    \"\"\"\n    if os.environ.get(\"TPV_DATA_PATH\", None):\n        p = str(os.environ.get(\"TPV_DATA_PATH\"))\n        _logger.info(f'Using TPV_DATA_PATH value read from the environment: \"{p}\"')\n        return Path(p)\n    if sys.platform == \"darwin\":\n        TPVPath = os.path.expanduser(\"~/TPVirtual\")\n    elif sys.platform == \"win32\":\n        TPVPath = os.path.expanduser(\"~/Documents/TPVirtual\")\n    else:\n        _logger.warning(\n            \"TrainingPeaks Virtual user folder can only be automatically detected on Windows and OSX\"\n        )\n        TPVPath = questionary.path(\n            'Please enter your TrainingPeaks Virtual data folder (by default, ends with \"TPVirtual\"): ',\n            default=str(default_path) if default_path else \"\",\n        ).ask()\n    return Path(TPVPath)\n</code></pre>"},{"location":"api/#utilities-utilspy","title":"Utilities (<code>utils.py</code>)","text":""},{"location":"api/#fit_file_faker.utils","title":"utils","text":"<p>Utility functions for Fit File Faker.</p> <p>This module provides utility functions including a monkey patch for fit_tool to handle malformed FIT files from certain manufacturers (e.g., COROS) and a CRC-16 checksum calculation function.</p> <p>The fit_tool patch is automatically applied when the fit_editor module is imported, making it transparent to users of the library.</p>"},{"location":"api/#fit_file_faker.utils._lenient_get_length_from_size","title":"_lenient_get_length_from_size","text":"<pre><code>_lenient_get_length_from_size(base_type: BaseType, size: int) -&gt; int\n</code></pre> <p>Lenient field length calculator that truncates instead of raising exceptions.</p> <p>This is a replacement for <code>fit_tool</code>'s <code>Field.get_length_from_size</code> that handles malformed FIT files more gracefully. Some manufacturers (e.g., COROS) create FIT files where field sizes are not exact multiples of their base type size. Instead of failing with an exception, this function truncates to the nearest valid length.</p> <p>Parameters:</p> Name Type Description Default <code>base_type</code> <code>BaseType</code> <p>The <code>BaseType</code> of the field (<code>STRING</code>, <code>BYTE</code>, <code>UINT8</code>, etc.).</p> required <code>size</code> <code>int</code> <p>The declared size of the field in bytes.</p> required <p>Returns:</p> Name Type Description <code>length</code> <code>int</code> <p>The field length (number of values, not bytes). For <code>STRING</code> and <code>BYTE</code> types, returns 0 for size 0 and 1 otherwise. For other types, returns <code>size // base_type.size</code> (truncated integer division).</p> Note <p>When truncation occurs (size not a multiple of <code>base_type.size</code>), a debug message is logged. This typically indicates a malformed FIT file but allows processing to continue.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Normal case: 8 bytes for UINT32 (4 bytes each) = length 2\n&gt;&gt;&gt; _lenient_get_length_from_size(BaseType.UINT32, 8)\n2\n</code></pre> <pre><code>&gt;&gt;&gt; # Malformed case: 7 bytes for UINT32 = length 1 (truncated)\n&gt;&gt;&gt; _lenient_get_length_from_size(BaseType.UINT32, 7)\n1\n</code></pre> Source code in <code>fit_file_faker/utils.py</code> <pre><code>def _lenient_get_length_from_size(base_type: \"BaseType\", size: int) -&gt; int:\n    \"\"\"Lenient field length calculator that truncates instead of raising exceptions.\n\n    This is a replacement for `fit_tool`'s `Field.get_length_from_size` that handles\n    malformed FIT files more gracefully. Some manufacturers (e.g., COROS) create\n    FIT files where field sizes are not exact multiples of their base type size.\n    Instead of failing with an exception, this function truncates to the nearest\n    valid length.\n\n    Args:\n        base_type: The `BaseType` of the field (`STRING`, `BYTE`, `UINT8`, etc.).\n        size: The declared size of the field in bytes.\n\n    Returns:\n        length: The field length (number of values, not bytes). For `STRING` and `BYTE`\n            types, returns 0 for size 0 and 1 otherwise. For other types, returns\n            `size // base_type.size` (truncated integer division).\n\n    Note:\n        When truncation occurs (size not a multiple of `base_type.size`), a debug\n        message is logged. This typically indicates a malformed FIT file but\n        allows processing to continue.\n\n    Examples:\n        &gt;&gt;&gt; # Normal case: 8 bytes for UINT32 (4 bytes each) = length 2\n        &gt;&gt;&gt; _lenient_get_length_from_size(BaseType.UINT32, 8)\n        2\n\n        &gt;&gt;&gt; # Malformed case: 7 bytes for UINT32 = length 1 (truncated)\n        &gt;&gt;&gt; _lenient_get_length_from_size(BaseType.UINT32, 7)\n        1\n    \"\"\"\n    if base_type == BaseType.STRING or base_type == BaseType.BYTE:\n        return 0 if size == 0 else 1\n    else:\n        length = size // base_type.size\n\n        if length * base_type.size != size:\n            _logger.debug(\n                f\"Field size ({size}) not multiple of type size ({base_type.size}), \"\n                f\"truncating to length {length}\"\n            )\n            return length\n\n        return length\n</code></pre>"},{"location":"api/#fit_file_faker.utils.apply_fit_tool_patch","title":"apply_fit_tool_patch","text":"<pre><code>apply_fit_tool_patch()\n</code></pre> <p>Apply monkey patch to <code>fit_tool</code> to handle malformed FIT files.</p> <p>Replaces <code>fit_tool</code>'s <code>Field.get_length_from_size</code> method with a more lenient version that truncates field lengths instead of raising exceptions when field sizes aren't exact multiples of their base type size.</p> <p>This patch is essential for processing FIT files from manufacturers like COROS that don't strictly follow the FIT specification. Without it, fit_tool would raise exceptions and refuse to process these files.</p> <p>The patch is automatically applied when the fit_editor module is imported, so users don't need to call this function manually.</p> Note <p>This is a global monkey patch that affects all subsequent <code>fit_tool</code> operations in the same Python process. It's applied once at module import time.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Typically called automatically, but can be invoked manually:\n&gt;&gt;&gt; from fit_file_faker.utils import apply_fit_tool_patch\n&gt;&gt;&gt; apply_fit_tool_patch()\n&gt;&gt;&gt; # Now fit_tool can handle COROS files without errors\n</code></pre> Source code in <code>fit_file_faker/utils.py</code> <pre><code>def apply_fit_tool_patch():\n    \"\"\"Apply monkey patch to `fit_tool` to handle malformed FIT files.\n\n    Replaces `fit_tool`'s `Field.get_length_from_size` method with a more lenient\n    version that truncates field lengths instead of raising exceptions when\n    field sizes aren't exact multiples of their base type size.\n\n    This patch is essential for processing FIT files from manufacturers like\n    COROS that don't strictly follow the FIT specification. Without it,\n    fit_tool would raise exceptions and refuse to process these files.\n\n    The patch is automatically applied when the fit_editor module is imported,\n    so users don't need to call this function manually.\n\n    Note:\n        This is a global monkey patch that affects all subsequent `fit_tool`\n        operations in the same Python process. It's applied once at module\n        import time.\n\n    Examples:\n        &gt;&gt;&gt; # Typically called automatically, but can be invoked manually:\n        &gt;&gt;&gt; from fit_file_faker.utils import apply_fit_tool_patch\n        &gt;&gt;&gt; apply_fit_tool_patch()\n        &gt;&gt;&gt; # Now fit_tool can handle COROS files without errors\n    \"\"\"\n    Field.get_length_from_size = staticmethod(_lenient_get_length_from_size)\n</code></pre>"},{"location":"api/#fit_file_faker.utils.fit_crc_get16","title":"fit_crc_get16","text":"<pre><code>fit_crc_get16(crc: int, byte: int) -&gt; int\n</code></pre> <p>Calculate FIT file CRC-16 checksum for a single byte.</p> <p>Implements the CRC-16 algorithm used by FIT files. This function processes one byte at a time and should be called repeatedly for each byte in the data to calculate a complete checksum.</p> <p>The algorithm uses a lookup table and processes the byte in two 4-bit nibbles (lower 4 bits first, then upper 4 bits) to compute the CRC.</p> <p>Parameters:</p> Name Type Description Default <code>crc</code> <code>int</code> <p>Current CRC value (16-bit unsigned integer). Use 0 for the first byte in the sequence.</p> required <code>byte</code> <code>int</code> <p>Byte value to add to the checksum (8-bit unsigned integer, 0-255).</p> required <p>Returns:</p> Type Description <code>int</code> <p>Updated CRC value (16-bit unsigned integer) after processing this byte.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Calculate CRC for a single byte\n&gt;&gt;&gt; crc = fit_crc_get16(0, 0x42)\n&gt;&gt;&gt; print(f\"CRC: {crc:#06x}\")\nCRC: 0x...\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Calculate CRC for a byte array\n&gt;&gt;&gt; def calculate_fit_crc(data: bytes) -&gt; int:\n...     '''Calculate CRC-16 for FIT file data.'''\n...     crc = 0\n...     for byte in data:\n...         crc = fit_crc_get16(crc, byte)\n...     return crc\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = b\"\\x0e\\x10\\x43\\x08\\x28\\x06\\x00\\x00\"\n&gt;&gt;&gt; checksum = calculate_fit_crc(data)\n</code></pre> Note <p>This is the standard CRC-16 algorithm used in FIT file headers and data records. It's primarily used for validation but is not currently required by <code>fit_file_faker</code> since <code>fit_tool</code> handles CRC calculation automatically.</p> Source code in <code>fit_file_faker/utils.py</code> <pre><code>def fit_crc_get16(crc: int, byte: int) -&gt; int:\n    \"\"\"Calculate FIT file CRC-16 checksum for a single byte.\n\n    Implements the CRC-16 algorithm used by FIT files. This function processes\n    one byte at a time and should be called repeatedly for each byte in the\n    data to calculate a complete checksum.\n\n    The algorithm uses a lookup table and processes the byte in two 4-bit\n    nibbles (lower 4 bits first, then upper 4 bits) to compute the CRC.\n\n    Args:\n        crc: Current CRC value (16-bit unsigned integer). Use 0 for the\n            first byte in the sequence.\n        byte: Byte value to add to the checksum (8-bit unsigned integer,\n            0-255).\n\n    Returns:\n        Updated CRC value (16-bit unsigned integer) after processing this byte.\n\n    Examples:\n        &gt;&gt;&gt; # Calculate CRC for a single byte\n        &gt;&gt;&gt; crc = fit_crc_get16(0, 0x42)\n        &gt;&gt;&gt; print(f\"CRC: {crc:#06x}\")\n        CRC: 0x...\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Calculate CRC for a byte array\n        &gt;&gt;&gt; def calculate_fit_crc(data: bytes) -&gt; int:\n        ...     '''Calculate CRC-16 for FIT file data.'''\n        ...     crc = 0\n        ...     for byte in data:\n        ...         crc = fit_crc_get16(crc, byte)\n        ...     return crc\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; data = b\"\\\\x0e\\\\x10\\\\x43\\\\x08\\\\x28\\\\x06\\\\x00\\\\x00\"\n        &gt;&gt;&gt; checksum = calculate_fit_crc(data)\n\n    Note:\n        This is the standard CRC-16 algorithm used in FIT file headers\n        and data records. It's primarily used for validation but is not\n        currently required by `fit_file_faker` since `fit_tool` handles CRC\n        calculation automatically.\n    \"\"\"\n    crc_table = [\n        0x0000,\n        0xCC01,\n        0xD801,\n        0x1400,\n        0xF001,\n        0x3C00,\n        0x2800,\n        0xE401,\n        0xA001,\n        0x6C00,\n        0x7800,\n        0xB401,\n        0x5000,\n        0x9C01,\n        0x8801,\n        0x4400,\n    ]\n\n    # Compute checksum of lower four bits of byte\n    tmp = crc_table[crc &amp; 0xF]\n    crc = (crc &gt;&gt; 4) &amp; 0x0FFF\n    crc = crc ^ tmp ^ crc_table[byte &amp; 0xF]\n\n    # Now compute checksum of upper four bits of byte\n    tmp = crc_table[crc &amp; 0xF]\n    crc = (crc &gt;&gt; 4) &amp; 0x0FFF\n    crc = crc ^ tmp ^ crc_table[(byte &gt;&gt; 4) &amp; 0xF]\n\n    return crc\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to FIT File Faker are documented here.</p> <p>This changelog is automatically generated from git commit messages using git-cliff. See our release history on GitHub for downloadable releases.</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#features","title":"Features","text":"<ul> <li>add FIT CRC-16 checksum calculation utility (9fa247c)</li> </ul>"},{"location":"changelog/#refactoring","title":"Refactoring","text":"<ul> <li> <p>Extract FIT file editing functionality into dedicated fit_editor.py module (issue #40) (c164854)</p> </li> <li> <p>Extract configuration management into dedicated config.py module (issue #40) (3868e26)</p> </li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li> <p>Refactor README and enhance documentation site (issue #41) (2efd4c7)</p> </li> <li> <p>Add comprehensive documentation site with MkDocs and automated deployment (#41) (031b19c)</p> </li> </ul>"},{"location":"changelog/#testing","title":"Testing","text":"<ul> <li>Add comprehensive test suite with pytest, fixtures, and CI workflow (issue #18) (f97fad5)</li> </ul>"},{"location":"changelog/#miscellaneous-tasks","title":"Miscellaneous Tasks","text":"<ul> <li>Implements conventional commit validation with gitlint (1f4c279)</li> </ul>"},{"location":"changelog/#124-2026-01-11","title":"1.2.4 (2026-01-11)","text":""},{"location":"changelog/#features_1","title":"Features","text":"<ul> <li>COROS: Add support for COROS FIT files with lenient field size validation (0f3ddde)</li> <li>MyWhoosh: Add support for MyWhoosh FIT files (manufacturer code 331) (72c5029)</li> </ul>"},{"location":"changelog/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>FIT files: Strip unknown field definitions before writing to prevent corruption (28265e2)</li> <li>FIT files: Fix Activity message ordering for COROS compatibility (0f3ddde)</li> <li>device info: Properly index device_index at 0 to fix images not showing on Garmin Connect (18186a7)</li> <li>CI: Fix broken \"test pypi\" release step (72c5029)</li> </ul>"},{"location":"changelog/#miscellaneous-tasks_1","title":"Miscellaneous Tasks","text":"<ul> <li>Update dependencies and add setuptools configuration (dc7e309)</li> <li>Bump version to 1.2.4 (b4d1877)</li> </ul>"},{"location":"changelog/#contributors","title":"Contributors","text":"<ul> <li>@dermarzel (MyWhoosh support)</li> </ul>"},{"location":"changelog/#123-2025-11-05","title":"1.2.3 (2025-11-05)","text":""},{"location":"changelog/#features_2","title":"Features","text":"<ul> <li>Hammerhead: Add support for Hammerhead Karoo devices (df6c3d6)</li> </ul>"},{"location":"changelog/#miscellaneous-tasks_2","title":"Miscellaneous Tasks","text":"<ul> <li>Bump version and update README (d606c18)</li> </ul>"},{"location":"changelog/#contributors_1","title":"Contributors","text":"<ul> <li>@lrybak (Hammerhead support)</li> </ul>"},{"location":"changelog/#122-2025-01-26","title":"1.2.2 (2025-01-26)","text":""},{"location":"changelog/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>FIT processing: Change to generate FileIdMessage rather than editing in place to ensure device is properly set (4026db3)</li> <li>FIT processing: Add FileCreator message for better compatibility (4026db3)</li> <li>TrainingPeaks Virtual: Fix issue with new TPV FIT file structure (#22) (391e1eb)</li> </ul>"},{"location":"changelog/#121-2025-01-07","title":"1.2.1 (2025-01-07)","text":""},{"location":"changelog/#cicd","title":"CI/CD","text":"<ul> <li>Don't run testpypi on non-tag pushes (5e83493)</li> <li>Update GitHub Actions configuration (a5028b0, e164d69)</li> </ul>"},{"location":"changelog/#miscellaneous-tasks_3","title":"Miscellaneous Tasks","text":"<ul> <li>Update version to 1.2.1 (1123c43)</li> </ul>"},{"location":"changelog/#120-2025-01-07","title":"1.2.0 (2025-01-07)","text":""},{"location":"changelog/#build-system","title":"Build System","text":"<ul> <li>Add UV package manager support (497d1ed)</li> <li>Add build/release GitHub Action (497d1ed)</li> <li>Rename project to fit-file-faker for PyPI (497d1ed)</li> </ul>"},{"location":"changelog/#miscellaneous-tasks_4","title":"Miscellaneous Tasks","text":"<ul> <li>Fix version number (4376a50)</li> <li>Bump version to 1.0.0 (4888355)</li> <li>Change install action command (b44334e)</li> </ul>"},{"location":"changelog/#111-2025-01-07","title":"1.1.1 (2025-01-07)","text":""},{"location":"changelog/#features_3","title":"Features","text":"<ul> <li>Zwift: Add support for Zwift FIT files (7efa28d)</li> <li>device info: Properly modify device manufacturer and product IDs (4d0d0a3)</li> </ul>"},{"location":"changelog/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>Don't use magic numbers for device identification (b6400c9)</li> <li>Remove unused variables (9415c62)</li> <li>Remove unneeded commented code (bc78a6e)</li> </ul>"},{"location":"changelog/#documentation_1","title":"Documentation","text":"<ul> <li>Update README with Zwift support information (09d8785)</li> <li>Update config example file (cd352c7)</li> <li>Various documentation improvements (450c7e6)</li> </ul>"},{"location":"changelog/#styling","title":"Styling","text":"<ul> <li>Code formatting improvements (132f22c)</li> </ul>"},{"location":"changelog/#110-2025-01-05","title":"1.1.0 (2025-01-05)","text":""},{"location":"changelog/#features_4","title":"Features","text":"<ul> <li>config: Implement configuration as dataclass stored in local JSON file (90c75c1)</li> <li>config: Add questionary for interactive config file generation (90c75c1)</li> <li>monitoring: Rename daemonise to monitor for clarity (90c75c1)</li> <li>monitoring: Use polling handler for monitor mode (better cross-platform support) (90c75c1)</li> <li>monitoring: Add monitor option to watch directory for new FIT files (c9491d7)</li> <li>monitoring: Add short pause after file creation to avoid CRC errors (63b7374)</li> <li>upload: Add dryrun option for testing without uploading (acf863e)</li> <li>upload: Add option to preinitialise the list of uploaded files (3ad9103)</li> <li>upload: Store credentials on first run (6d5e4d2)</li> <li>upload: Set default upload directory to configured TPV user dir (c537bcd)</li> <li>upload: Change uploaded files tracking to be local to FIT files directory (c9491d7)</li> <li>platform: Add macOS compatibility (3343374)</li> <li>platform: Add minimum Python version check (90c75c1)</li> </ul>"},{"location":"changelog/#bug-fixes_3","title":"Bug Fixes","text":"<ul> <li>FIT processing: Set FitFileBuilder autodefine param to True, fixes issue with Strava FIT files (d7a2da3)</li> <li>upload: Fix upload all bug when running on a directory other than cwd (bd704e6)</li> <li>upload: Fix preinitialise bug (4c8de1f)</li> <li>platform: Fix TPV path issues (5847de9, 8b94533)</li> <li>platform: Fix FITfiles directory detection (c613c36)</li> </ul>"},{"location":"changelog/#miscellaneous-tasks_5","title":"Miscellaneous Tasks","text":"<ul> <li>Move .garth directory to script folder rather than FITFiles folder (90c75c1)</li> <li>Better organize main code path (90c75c1)</li> <li>Remove .env file (90c75c1)</li> <li>Update requirements.txt (53ced03)</li> <li>Bump Garth version (358409f)</li> </ul>"},{"location":"changelog/#documentation_2","title":"Documentation","text":"<ul> <li>Update README with new features and improved help output (e3480ff, 90c75c1)</li> <li>Add example .config file (2296c38)</li> </ul>"},{"location":"changelog/#styling_1","title":"Styling","text":"<ul> <li>Implement ruff formatting and import order (90c75c1)</li> <li>Fix spelling issues (c613c36, e2f545c)</li> </ul>"},{"location":"changelog/#contributors_2","title":"Contributors","text":"<ul> <li>@benjmarshall (multiple contributions including daemon mode, config improvements, and bug fixes)</li> </ul>"},{"location":"changelog/#103-2024-12-03","title":"1.0.3 (2024-12-03)","text":""},{"location":"changelog/#bug-fixes_4","title":"Bug Fixes","text":"<ul> <li>dependencies: Update garth version requirement to address compatibility issue (e413e23)</li> <li>Resolves garth issue #73</li> </ul>"},{"location":"changelog/#102-2024-10-31","title":"1.0.2 (2024-10-31)","text":""},{"location":"changelog/#testing_1","title":"Testing","text":"<ul> <li>Add install tests for CI/CD pipeline (91ba6f5)</li> </ul>"},{"location":"changelog/#miscellaneous-tasks_6","title":"Miscellaneous Tasks","text":"<ul> <li>Update requirements.txt (47133a1)</li> </ul>"},{"location":"changelog/#101-2024-05-28","title":"1.0.1 (2024-05-28)","text":""},{"location":"changelog/#bug-fixes_5","title":"Bug Fixes","text":"<ul> <li>Windows: Add tempfile options to workaround Windows permission issue (#1) (b3ae2cf)</li> </ul>"},{"location":"changelog/#documentation_3","title":"Documentation","text":"<ul> <li>Update README with required Python version (fd82175)</li> </ul>"},{"location":"changelog/#100-2024-05-22","title":"1.0.0 (2024-05-22)","text":""},{"location":"changelog/#features_5","title":"Features","text":"<ul> <li>Initial Release: First public release of Fit File Faker (7c78e47)</li> <li>Modify FIT files to appear as Garmin Edge 830 device</li> <li>Support for TrainingPeaks Virtual (formerly indieVelo) FIT files</li> <li>Upload modified files to Garmin Connect</li> <li>Batch processing of multiple FIT files</li> <li>Credential storage and authentication</li> </ul>"},{"location":"developer-guide/","title":"Developer Guide","text":"<p>This guide provides comprehensive information for developers contributing to Fit File Faker, including architecture, testing, and release processes.</p>"},{"location":"developer-guide/#getting-started-with-development","title":"Getting Started with Development","text":""},{"location":"developer-guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12 or higher</li> <li>uv (preferred) or pip</li> <li>Git</li> </ul>"},{"location":"developer-guide/#development-setup","title":"Development Setup","text":"<p>Clone the repository and install dependencies:</p> uv (Recommended)pip <pre><code>git clone https://github.com/jat255/Fit-File-Faker.git\ncd Fit-File-Faker\nuv sync  # Installs all dependencies\n</code></pre> <pre><code>git clone https://github.com/jat255/Fit-File-Faker.git\ncd Fit-File-Faker\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\npip install .\n</code></pre>"},{"location":"developer-guide/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>The project uses pre-commit to run code quality checks before committing. After setting up your development environment:</p> <pre><code>uv run pre-commit install\nuv run pre-commit install --hook-type commit-msg\n</code></pre> <p>This automatically runs the following checks:</p> <ul> <li><code>ruff check</code> and <code>ruff format</code>: Code linting and formatting on staged files</li> <li><code>gitlint</code>: Validates commit messages follow Conventional Commits format</li> </ul> <p>Run hooks manually on all files:</p> <pre><code>uv run pre-commit run --all-files\n</code></pre>"},{"location":"developer-guide/#common-development-commands","title":"Common Development Commands","text":"<pre><code># Show help\nfit-file-faker -h\n\n# Initial configuration (interactive)\nfit-file-faker -s\n\n# Edit a single FIT file\nfit-file-faker path/to/file.fit\n\n# Edit and upload to Garmin Connect\nfit-file-faker -u path/to/file.fit\n\n# Upload all new files in configured directory\nfit-file-faker -ua\n\n# Monitor directory for new files\nfit-file-faker -m\n\n# Dry run (no changes or uploads)\nfit-file-faker -d path/to/file.fit\n</code></pre>"},{"location":"developer-guide/#linting","title":"Linting","text":"<pre><code># Run ruff (configured in dev dependencies)\nruff check .\nruff format .\n</code></pre>"},{"location":"developer-guide/#build-and-distribution","title":"Build and Distribution","text":"<pre><code># Build the package for testing\nuv build\n\n# Install locally for testing\npip install -e .\n</code></pre>"},{"location":"developer-guide/#release-strategy","title":"Release strategy","text":"<p>Releases are done built and pushed to PyPI automatically by the GitHub action in <code>.github/workflows/publish_and_release.yml</code>, which is triggered whenever a tag is pushed to the repository.</p>"},{"location":"developer-guide/#architecture-overview","title":"Architecture Overview","text":""},{"location":"developer-guide/#package-structure","title":"Package Structure","text":"<p>The application is organized as a modular Python package (<code>fit_file_faker/</code>) with ~998 total lines across five files:</p> <pre><code>fit_file_faker/\n\u251c\u2500\u2500 __init__.py           # Package initialization\n\u251c\u2500\u2500 app.py                # Main application, CLI, uploads, monitoring\n\u251c\u2500\u2500 config.py             # Configuration management\n\u251c\u2500\u2500 fit_editor.py         # FIT file editing core logic\n\u2514\u2500\u2500 utils.py              # Utility functions and monkey patches\n</code></pre> <p>Entry Point: <code>fit_file_faker.app:run</code> (defined in <code>pyproject.toml</code>)</p> <p>Design Philosophy</p> <p>The modular structure improves maintainability while keeping the codebase compact:</p> <ul> <li>Separation of concerns (config, editing, upload, utilities)</li> <li>Easier testing (each module can be tested independently)</li> <li>Clear boundaries between functionality</li> <li>Still simple to understand and contribute to</li> </ul>"},{"location":"developer-guide/#core-workflow","title":"Core Workflow","text":"<p>The tool follows a six-step process:</p> <ol> <li>Read FIT file: Uses the <code>fit_tool</code> library to parse binary FIT files</li> <li>Apply fit_tool patch: Applies monkey patch from <code>utils.py</code> to handle malformed FIT files (e.g., COROS)</li> <li>Identify device messages: Locates <code>FileIdMessage</code>, <code>FileCreatorMessage</code>, and <code>DeviceInfoMessage</code> records</li> <li> <p>Rewrite manufacturer/product IDs: Changes manufacturer codes from:</p> <ul> <li><code>DEVELOPMENT</code> (255)</li> <li><code>ZWIFT</code></li> <li><code>WAHOO_FITNESS</code></li> <li><code>PEAKSWARE</code></li> <li><code>HAMMERHEAD</code></li> <li><code>COROS</code></li> <li><code>MYWHOOSH</code> (331)</li> </ul> <p>to <code>GARMIN</code> (1) with Edge 830 product ID (3122)</p> </li> <li> <p>Rebuild FIT file: Uses <code>FitFileBuilder</code> to reconstruct the file with modified messages</p> </li> <li>Upload (optional): Authenticates to Garmin Connect via <code>garth</code> library and uploads the modified file</li> </ol>"},{"location":"developer-guide/#module-breakdown","title":"Module Breakdown","text":""},{"location":"developer-guide/#configpy-configuration-management","title":"<code>config.py</code> - Configuration Management","text":"<ul> <li><code>Config</code> dataclass: Holds <code>garmin_username</code>, <code>garmin_password</code>, <code>fitfiles_path</code></li> <li><code>ConfigManager</code> class: Handles config file I/O, validation, and interactive building<ul> <li><code>_load_config()</code>: Loads or creates configuration</li> <li><code>save_config()</code>: Persists configuration to disk</li> <li><code>is_valid()</code>: Validates configuration completeness</li> <li><code>build_config_file()</code>: Interactively builds configuration</li> </ul> </li> <li>Stored in platform-specific user config directory (via <code>platformdirs</code>) as <code>.config.json</code></li> <li><code>get_fitfiles_path()</code>: Auto-detects TrainingPeaks Virtual directories</li> <li><code>get_tpv_folder()</code>: Platform-specific TPV directory detection</li> <li><code>PathEncoder</code>: Custom JSON encoder for Path objects</li> </ul>"},{"location":"developer-guide/#fit_editorpy-fit-file-editing","title":"<code>fit_editor.py</code> - FIT File Editing","text":"<ul> <li><code>FitEditor</code> class: Main editor with logging filter for fit_tool warnings<ul> <li><code>edit_fit()</code>: Main function that reads, modifies, and saves FIT files</li> <li><code>rewrite_file_id_message()</code>: Converts FileIdMessage to Garmin Edge 830 format</li> <li><code>strip_unknown_fields()</code>: Handles unknown field definitions to prevent file corruption</li> <li><code>_should_modify_manufacturer()</code>: Determines if manufacturer should be changed</li> <li><code>_should_modify_device_info()</code>: Determines if device info should be changed</li> <li><code>get_date_from_fit()</code>: Extracts creation date from FIT file</li> <li><code>print_message()</code>: Debug output for FIT messages</li> </ul> </li> <li><code>FitFileLogFilter</code>: Custom logging filter to suppress noisy fit_tool warnings</li> <li>Device info messages are rewritten to Garmin Edge 830</li> <li>Activity data is always preserved (records, laps, sessions) - only modifies device metadata</li> <li>Special handling for Activity messages (reordered to end for COROS compatibility)</li> </ul>"},{"location":"developer-guide/#apppy-main-application","title":"<code>app.py</code> - Main Application","text":"<ul> <li>CLI argument parsing and validation (using <code>argparse</code>)</li> <li><code>run()</code>: Main entry point with Python version checking</li> <li><code>upload()</code>: Garmin Connect upload with OAuth authentication via <code>garth</code><ul> <li>Handles authentication and credential prompting</li> <li>Caches credentials in <code>.garth</code> directory</li> <li>Gracefully handles HTTP 409 conflicts (duplicate activities)</li> </ul> </li> <li><code>upload_all()</code>: Batch processes all FIT files in a directory<ul> <li>Maintains <code>.uploaded_files.json</code> to track processed files</li> <li>Creates temporary files for uploads (discarded after upload)</li> </ul> </li> <li><code>monitor()</code>: Watches directory for new FIT files using <code>watchdog</code></li> <li><code>NewFileEventHandler</code>: Event handler class for monitoring mode<ul> <li>5-second delay after file creation to ensure write completion</li> <li>Automatically processes and uploads new files</li> </ul> </li> <li>Rich console output with colored logs and tracebacks</li> </ul>"},{"location":"developer-guide/#utilspy-utility-functions","title":"<code>utils.py</code> - Utility Functions","text":"<ul> <li><code>apply_fit_tool_patch()</code>: Monkey patches fit_tool to handle malformed FIT files</li> <li><code>_lenient_get_length_from_size()</code>: Lenient field size validation (truncates instead of raising)</li> <li><code>fit_crc_get16()</code>: FIT file CRC-16 checksum calculation</li> <li>Required for COROS and other manufacturers with non-standard FIT files</li> </ul>"},{"location":"developer-guide/#supported-source-platforms","title":"Supported Source Platforms","text":"<p>The tool recognizes and modifies FIT files from:</p> Platform Manufacturer Code Notes TrainingPeaks Virtual <code>DEVELOPMENT</code> or <code>PEAKSWARE</code> Formerly indieVelo Zwift <code>ZWIFT</code> Popular virtual cycling platform Wahoo devices <code>WAHOO_FITNESS</code> Wahoo bike computers Hammerhead Karoo <code>HAMMERHEAD</code> Karoo bike computers MyWhoosh <code>331</code> Not in <code>fit_tool</code>'s enum COROS <code>COROS</code> Requires <code>fit_tool</code> patch for malformed fields"},{"location":"developer-guide/#logging-and-output","title":"Logging and Output","text":"<ul> <li>Uses <code>rich</code> library for formatted console output (configured in <code>app.py</code>)</li> <li><code>RichHandler</code> for colored, timestamped logs with traceback support</li> <li>Custom <code>FitFileLogFilter</code> in <code>fit_editor.py</code> to suppress fit_tool's \"actual:\" warnings</li> <li>Debug mode (<code>-v</code>) provides detailed message-by-message processing logs</li> <li>Separate log level configuration for different modules (urllib3, oauth1_auth, watchdog, asyncio, etc.)</li> </ul>"},{"location":"developer-guide/#important-implementation-notes","title":"Important Implementation Notes","text":""},{"location":"developer-guide/#fit-file-structure","title":"FIT File Structure","text":"<p>Critical Information</p> <p>FIT files contain a series of messages (records). Each data message must be preceded by a definition message.</p> <p>When rewriting messages, always write: <pre><code>DefinitionMessage.from_data_message(message)\n</code></pre> then the message itself.</p> <p><code>FitFileBuilder(auto_define=True)</code> handles definition messages automatically when <code>add()</code> is called.</p>"},{"location":"developer-guide/#edge-830-simulation","title":"Edge 830 Simulation","text":"<p>The tool specifically emulates a Garmin Edge 830 with these values:</p> <ul> <li>Manufacturer: 1 (<code>GARMIN</code>)</li> <li>Product: 3122 (<code>EDGE_830</code>)</li> <li>Software version: 975 (in <code>FileCreatorMessage</code>)</li> <li>Hardware version: 255</li> </ul>"},{"location":"developer-guide/#file-naming-convention","title":"File Naming Convention","text":"<p>Modified files are saved as <code>{original_stem}_modified.fit</code> unless uploading in batch mode (which uses temp files).</p>"},{"location":"developer-guide/#platform-detection","title":"Platform Detection","text":"<p>The tool auto-detects TrainingPeaks Virtual user directories on:</p> <ul> <li>macOS: <code>~/TPVirtual</code></li> <li>Windows: <code>~/Documents/TPVirtual</code></li> <li>Linux: Prompts user for path (no auto-detection)</li> </ul> <p>Override with <code>TPV_DATA_PATH</code> environment variable.</p>"},{"location":"developer-guide/#testing","title":"Testing","text":""},{"location":"developer-guide/#quick-start","title":"Quick Start","text":"<pre><code># Run all tests\npython3 run_tests.py\n\n# Run with coverage (HTML report)\npython3 run_tests.py --html\n</code></pre>"},{"location":"developer-guide/#test-suite-overview","title":"Test Suite Overview","text":"<p>The test suite includes 53+ tests with 100% code coverage for all major functionality.</p>"},{"location":"developer-guide/#test-file-structure","title":"Test File Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py              # Shared fixtures and test configuration\n\u251c\u2500\u2500 test_fit_editor.py       # FIT editing tests\n\u251c\u2500\u2500 test_config.py           # Configuration tests\n\u251c\u2500\u2500 test_app.py              # Application and upload tests\n\u251c\u2500\u2500 test_utils.py            # Utility function tests\n\u2514\u2500\u2500 files/                   # Test FIT files from various platforms\n    \u251c\u2500\u2500 tpv_20250111.fit\n    \u251c\u2500\u2500 tpv_20251120.fit\n    \u251c\u2500\u2500 zwift_20250401.fit\n    \u251c\u2500\u2500 mywhoosh_20260111.fit\n    \u251c\u2500\u2500 karoo_20251119.fit\n    \u2514\u2500\u2500 coros_20251118.fit\n</code></pre>"},{"location":"developer-guide/#test-isolation","title":"Test Isolation","text":"<p>All tests should be completely isolated from a real environment:</p> <ul> <li>\u2705 Config directories redirected to temporary locations</li> <li>\u2705 Cache directories use temp space</li> <li>\u2705 No network calls (all external services mocked)</li> <li>\u2705 Automatic cleanup after each test</li> <li>\u2705 Safe to run in parallel</li> </ul> <p>The <code>isolate_config_dirs</code> autouse fixture in <code>conftest.py</code> ensures that no test ever touches:</p> <ul> <li>Your real Garmin credentials</li> <li>Your actual FIT files</li> <li>Your user configuration directory</li> <li>Your system cache</li> </ul>"},{"location":"developer-guide/#test-fixtures-and-helpers","title":"Test Fixtures and Helpers","text":"<p>The test suite uses shared fixtures in <code>conftest.py</code> to reduce duplication:</p>"},{"location":"developer-guide/#shared-mock-classes","title":"Shared Mock Classes","text":"<ul> <li><code>MockQuestion</code>: Mock for questionary interactive prompts</li> <li><code>MockGarthHTTPError</code>: Configurable HTTP error mock with status codes</li> <li><code>MockGarthException</code>: Standard Garth exception for auth flow testing</li> </ul>"},{"location":"developer-guide/#shared-fixtures","title":"Shared Fixtures","text":"<ul> <li><code>mock_garth_basic</code>: Basic Garmin Connect mock for successful operations</li> <li><code>mock_garth_with_login</code>: Garmin mock requiring authentication</li> <li><code>isolate_config_dirs</code> (autouse): Automatically isolates all tests from real user directories</li> <li><code>temp_dir</code>: Creates temporary directories for test outputs</li> <li><code>mock_config_file</code>: Creates mock configuration files</li> </ul>"},{"location":"developer-guide/#mocking-strategy","title":"Mocking Strategy","text":""},{"location":"developer-guide/#external-services","title":"External Services","text":"<ul> <li>Garmin Connect (<code>garth</code>): Mocked using <code>sys.modules</code> patching with shared fixtures</li> <li>User prompts (<code>questionary</code>): Mocked using <code>MockQuestion</code> helper class</li> <li>File system (<code>platformdirs</code>): Automatically redirected to temp directories via <code>isolate_config_dirs</code></li> </ul> <p>Why sys.modules for garth?</p> <p>The <code>garth</code> library is imported inside functions (lazy import), so we use <code>patch.dict('sys.modules')</code> to inject mock modules that get imported at runtime.</p>"},{"location":"developer-guide/#running-tests","title":"Running Tests","text":""},{"location":"developer-guide/#using-the-helper-script","title":"Using the Helper Script","text":"<pre><code># Basic usage\npython3 run_tests.py\n\n# With coverage\npython3 run_tests.py --coverage\n\n# HTML coverage report\npython3 run_tests.py --html\n\n# Verbose output\npython3 run_tests.py -v\n\n# Specific test file\npython3 run_tests.py tests/test_fit_editor.py\n\n# Specific test\npython3 run_tests.py tests/test_fit_editor.py::TestFitEditor::test_edit_tpv_fit_file\n\n# Combined options\npython3 run_tests.py --coverage --html -v\n</code></pre>"},{"location":"developer-guide/#using-pytest-directly","title":"Using pytest Directly","text":"<pre><code># Run all tests\nuv run pytest tests/\n\n# With coverage\nuv run pytest tests/ --cov=fit_file_faker --cov-report=html\n\n# Verbose\nuv run pytest tests/ -v\n</code></pre>"},{"location":"developer-guide/#continuous-integration","title":"Continuous Integration","text":"<p>The test suite runs automatically on GitHub Actions for:</p> <ul> <li>Python versions: 3.12, 3.13, 3.14</li> <li>Operating systems: Ubuntu, macOS, Windows</li> <li>Triggers: Push to main/develop/refactor branches, pull requests</li> </ul> <p>Workflow file: <code>.github/workflows/test.yml</code></p> <p>Coverage reports are uploaded to Codecov on successful Ubuntu + Python 3.12 runs.</p>"},{"location":"developer-guide/#adding-new-tests","title":"Adding New Tests","text":"<p>When adding support for a new platform:</p> <ol> <li>Add the FIT file to <code>tests/files/</code> (sanitize it of any personally identifiable information)</li> <li>Create a fixture in <code>conftest.py</code>:    <pre><code>@pytest.fixture\ndef new_platform_fit_file(test_files_dir):\n    return test_files_dir / \"new_platform.fit\"\n</code></pre></li> <li>Add a test in <code>test_fit_editor.py</code>:    <pre><code>def test_edit_new_platform_fit_file(self, fit_editor, new_platform_fit_file, temp_dir):\n    output_file = temp_dir / \"new_platform_modified.fit\"\n    result = fit_editor.edit_fit(new_platform_fit_file, output=output_file)\n\n    assert result == output_file\n    assert output_file.exists()\n\n    # Verify modifications\n    modified_fit = FitFile.from_file(str(output_file))\n    for record in modified_fit.records:\n        if isinstance(record.message, FileIdMessage):\n            assert record.message.manufacturer == Manufacturer.GARMIN.value\n</code></pre></li> </ol>"},{"location":"developer-guide/#test-best-practices","title":"Test Best Practices","text":"<ol> <li>Always use fixtures for test data (don't hardcode paths)</li> <li>Mock external services (no real network calls)</li> <li>Use temp directories for output files</li> <li>Test both success and failure paths</li> <li>Keep tests independent (no shared state)</li> <li>Use descriptive test names that explain what's being tested</li> <li>Verify behavior, not implementation (test outcomes, not internals)</li> </ol>"},{"location":"developer-guide/#contributing","title":"Contributing","text":"<p>We welcome contributions! Here's how to get started:</p>"},{"location":"developer-guide/#contribution-workflow","title":"Contribution Workflow","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch: <code>git checkout -b feature/your-feature-name</code></li> <li>Make your changes</li> <li>Run tests: <code>python3 run_tests.py --coverage</code></li> <li>Run linting: <code>ruff check . &amp;&amp; ruff format .</code></li> <li>Commit your changes following conventional commits</li> <li>Push to your fork: <code>git push origin feature/your-feature-name</code></li> <li>Open a Pull Request</li> </ol>"},{"location":"developer-guide/#commit-message-format","title":"Commit Message Format","text":"<p>We use Conventional Commits for automatic changelog generation. Commit messages are automatically validated by gitlint through pre-commit hooks.</p> <p>Required format: <pre><code>&lt;type&gt;: &lt;description&gt;\n\n[optional body]\n\n[optional footer]\n</code></pre></p> <p>Allowed types:</p> <ul> <li><code>feat:</code> New features</li> <li><code>minor-feat:</code> New minor features</li> <li><code>fix:</code> Bug fixes</li> <li><code>docs:</code> Documentation changes</li> <li><code>test:</code> Test additions or modifications</li> <li><code>refactor:</code> Code refactoring</li> <li><code>chore:</code> Maintenance tasks</li> <li><code>ci:</code> CI/CD changes</li> <li><code>build:</code> Build system changes</li> <li><code>perf:</code> Performance improvements</li> <li><code>style:</code> Code style changes</li> <li><code>revert:</code> Revert previous commits</li> </ul> <p>Example: <pre><code>feat: add support for COROS FIT files\n\nAdd manufacturer code recognition and device ID modification for COROS\ndevices to enable Garmin Connect Training Effect calculations.\n</code></pre></p> <p>Commit Message Validation</p> <p>The pre-commit hook will reject commits that don't follow the conventional commits format. The hook configuration is in <code>.gitlint</code> and validates:</p> <ul> <li>Type is one of the allowed types</li> <li>Format follows <code>type(optional-scope): description</code></li> <li>Title is \u2264100 characters</li> <li>Body is optional (not required)</li> </ul>"},{"location":"developer-guide/#code-style","title":"Code Style","text":"<ul> <li>Follow PEP 8</li> <li>Use <code>ruff</code> for formatting and linting</li> <li>Maximum line length: 100 characters (configured in <code>pyproject.toml</code>)</li> <li>Use type hints where appropriate</li> </ul>"},{"location":"developer-guide/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<ul> <li>Provide a clear description of the changes</li> <li>Reference any related issues</li> <li>Ensure all tests pass</li> <li>Maintain 100% code coverage</li> <li>Update documentation if needed</li> </ul>"},{"location":"developer-guide/#release-process","title":"Release Process","text":"<p>Releases are automated via <code>.github/workflows/publish_and_release.yml</code>:</p> <ol> <li>All pushes build the package and publish to TestPyPI</li> <li>Tag pushes (e.g., <code>v1.2.3</code>) trigger PyPI publication and GitHub Release creation</li> <li>Version is defined in <code>pyproject.toml</code> and must be manually updated before tagging</li> </ol>"},{"location":"developer-guide/#to-release-a-new-version","title":"To Release a New Version","text":"<ol> <li> <p>Update version in <code>pyproject.toml</code>:    <pre><code>version = \"1.2.5\"\n</code></pre></p> </li> <li> <p>Commit the version change:    <pre><code>git add pyproject.toml\ngit commit -m \"chore: bump version to 1.2.5\"\n</code></pre></p> </li> <li> <p>Create and push a git tag with a detailed message:    <pre><code>git tag v1.2.5 -m \"Release v1.2.5: Add support for new platforms\n\nThis release includes support for MyWhoosh and COROS devices, along with\nimproved error handling and comprehensive test coverage.\"\ngit push origin main\ngit push origin v1.2.5\n</code></pre></p> <p>Tag Messages in Changelog</p> <p>Detailed tag messages (using the <code>-m</code> flag) will be rendered in the auto-generated changelog and GitHub Release notes. Use this to provide release highlights, breaking changes, or upgrade instructions that won't fit in individual commit messages.</p> </li> <li> <p>Automated steps (handled by GitHub Actions):</p> <ul> <li>Build package</li> <li>Publish to PyPI</li> <li>Create GitHub Release</li> <li>Generate changelog</li> <li>Deploy documentation</li> </ul> </li> </ol>"},{"location":"developer-guide/#version-numbering","title":"Version Numbering","text":"<p>We follow Semantic Versioning:</p> <ul> <li>MAJOR (1.x.x): Breaking changes</li> <li>MINOR (x.1.x): New features (backwards-compatible)</li> <li>PATCH (x.x.1): Bug fixes (backwards-compatible)</li> </ul>"},{"location":"developer-guide/#documentation","title":"Documentation","text":"<p>The project has a comprehensive documentation site built with MkDocs Material and hosted on GitHub Pages.</p>"},{"location":"developer-guide/#documentation-site","title":"Documentation Site","text":"<ul> <li>URL: https://jat255.github.io/Fit-File-Faker/</li> <li>Framework: MkDocs with Material theme</li> <li>Deployment: Automated via GitHub Actions to <code>gh-pages</code> branch</li> <li>Changelog: Auto-generated from git commits using git-cliff</li> </ul>"},{"location":"developer-guide/#documentation-structure","title":"Documentation Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md              # Home page (user guide, from README.md)\n\u251c\u2500\u2500 developer-guide.md    # Developer guide (this file)\n\u251c\u2500\u2500 changelog.md          # Auto-generated changelog\n\u2514\u2500\u2500 assets/               # Images, custom CSS, and other assets\n</code></pre>"},{"location":"developer-guide/#building-documentation-locally","title":"Building Documentation Locally","text":""},{"location":"developer-guide/#prerequisites_1","title":"Prerequisites","text":"<p>Install documentation dependencies:</p> <pre><code># Using uv (recommended)\nuv sync --group docs\n\n# Using pip\npip install mkdocs mkdocs-material mkdocs-minify-plugin\n</code></pre>"},{"location":"developer-guide/#local-development","title":"Local Development","text":"<p>Option 1: Using the build script (Recommended)</p> <p>The <code>build_docs.sh</code> script generates the complete changelog (including historical releases) and builds/serves the documentation, mirroring the CI/CD workflow:</p> <pre><code># Build static documentation with changelog\n./build_docs.sh\n\n# Serve with live reload for development\n./build_docs.sh serve\n\n# Opens at http://127.0.0.1:8000\n# Changes to docs/ files will automatically reload the browser\n</code></pre> <p>Option 2: Using mkdocs directly</p> <pre><code># Serve documentation locally with live reload\nuv run mkdocs serve\n\n# Opens at http://127.0.0.1:8000\n# Changes to docs/ files will automatically reload the browser\n</code></pre> <p>Changelog Generation</p> <p>When using <code>mkdocs serve</code> directly, the changelog won't be regenerated. Use <code>./build_docs.sh serve</code> to include the latest changelog in your local preview.</p>"},{"location":"developer-guide/#build-static-site","title":"Build Static Site","text":"<pre><code># Using the build script (includes changelog generation)\n./build_docs.sh\n\n# Or build directly with mkdocs (without changelog update)\nmkdocs build\n\n# The generated site can be found in the site/ directory\n</code></pre>"},{"location":"developer-guide/#deploy-to-github-pages","title":"Deploy to GitHub Pages","text":"<pre><code># Deploy to gh-pages branch (requires push access)\nmkdocs gh-deploy\n</code></pre> <p>Manual Deployment</p> <p>Manual deployment via <code>mkdocs gh-deploy</code> is rarely needed since documentation is automatically deployed by GitHub Actions. Only use this if the automated deployment fails.</p>"},{"location":"developer-guide/#documentation-automation","title":"Documentation Automation","text":"<p>Documentation automatically rebuilds and deploys in two scenarios:</p>"},{"location":"developer-guide/#1-documentation-changes","title":"1. Documentation Changes","text":"<p>When changes are pushed to <code>main</code> branch that affect: - <code>docs/**</code> (any documentation files) - <code>mkdocs.yml</code> (MkDocs configuration) - <code>pyproject.toml</code> (contains git-cliff changelog generation config)</p> <p>Workflow: <code>.github/workflows/docs.yml</code></p> <p>This workflow:</p> <ol> <li>Checks out the repository</li> <li>Sets up Python and installs dependencies</li> <li>Builds the documentation with <code>mkdocs build</code></li> <li>Deploys to GitHub Pages (<code>gh-pages</code> branch)</li> </ol>"},{"location":"developer-guide/#2-release-process","title":"2. Release Process","text":"<p>After a new release is created (when a tag like <code>v1.2.5</code> is pushed):</p> <p>Workflow: <code>.github/workflows/publish_and_release.yml</code></p> <p>This workflow:</p> <ol> <li>Builds and publishes the package to PyPI</li> <li>Creates a GitHub Release</li> <li>Generates the changelog using <code>git-cliff</code></li> <li>Deploys updated documentation</li> </ol>"},{"location":"developer-guide/#changelog-generation","title":"Changelog Generation","text":"<p>The changelog is automatically generated using git-cliff based on conventional commit messages.</p>"},{"location":"developer-guide/#configuration","title":"Configuration","text":"<p>Changelog generation is configured in <code>pyproject.toml</code> under the <code>[tool.git-cliff.*]</code> sections:</p> <ul> <li>Commit parsers: Categorize commits by type (feat, fix, docs, etc.)</li> <li>Format: Markdown with links to commits and releases</li> <li>Sections: Features, Bug Fixes, Documentation, etc.</li> <li>Skipped tags: Old releases (v1.0.0 - v1.2.4) that predate conventional commits</li> </ul>"},{"location":"developer-guide/#historical-releases","title":"Historical Releases","text":"<p>The project adopted conventional commits starting with v1.3.0. Earlier releases (v1.0.0 - v1.2.4) don't follow this format, so they are handled specially:</p> <p>Configuration in <code>pyproject.toml</code>: <pre><code>[tool.git-cliff.git]\n# Skip old tags that predate conventional commits\nskip_tags = \"v0.0.1-beta.1|v1.0.0|v1.0.1|v1.0.2|v1.0.3|v1.1.0|v1.1.1|v1.2.0|v1.2.1|v1.2.2|v1.2.3|v1.2.4\"\n</code></pre></p> <p>Workflow integration:</p> <ol> <li>Git-cliff generates the changelog from conventional commits only (v1.3.0+)</li> <li>The historical changelog from <code>docs/.changelog_pre_1.3.0.md</code> is appended</li> <li>Result: Complete changelog with both new and legacy releases</li> </ol> <p>This approach: - \u2705 Keeps the generated changelog clean with conventional commits - \u2705 Preserves historical release information - \u2705 Works automatically in both CI/CD and local builds (<code>./build_docs.sh</code>)</p>"},{"location":"developer-guide/#conventional-commits","title":"Conventional Commits","text":"<p>For commits to appear in the changelog, they must follow the Conventional Commits format:</p> <pre><code>&lt;type&gt;: &lt;description&gt;\n\n[optional body]\n\n[optional footer]\n</code></pre> <p>Types:</p> <ul> <li><code>feat:</code> - New features</li> <li><code>minor-feat:</code> - New minor features</li> <li><code>fix:</code> - Bug fixes</li> <li><code>docs:</code> - Documentation changes</li> <li><code>test:</code> - Test additions or modifications</li> <li><code>refactor:</code> - Code refactoring</li> <li><code>chore:</code> - Maintenance tasks</li> <li><code>ci:</code> - CI/CD changes</li> <li><code>build:</code> - Build system changes</li> </ul> <p>Example: <pre><code>feat: add support for COROS FIT files\n\nAdd lenient field size validation to handle malformed FIT files from\nCOROS devices. This enables Training Effect calculations for COROS\nactivities uploaded to Garmin Connect.\n</code></pre></p>"},{"location":"developer-guide/#manual-changelog-generation","title":"Manual Changelog Generation","text":"<p>To generate the changelog locally (for testing):</p> <pre><code># Install git-cliff\ncargo install git-cliff\n# or\nbrew install git-cliff\n\n# Generate changelog (reads config from pyproject.toml automatically)\ngit cliff --output docs/changelog.md\n\n# Generate changelog for specific version range\ngit cliff --output docs/changelog.md v1.3.0..HEAD\n</code></pre> <p>Github API limits</p> <p><code>git cliff</code> will make requests to the Github API to get information about various bits of information, and without authentication, the API limit is very low, so you may see errors such as: <pre><code>thread 'main' (37956221) panicked at git-cliff-core/src/changelog.rs:558:18:\nCould not get github metadata: HttpClientError(reqwest::Error { kind: Status(403, None), url: \"https://api.github.com/repos/jat255/Fit-File-Faker/commits?per_page=100&amp;page=0&amp;sha=v1.2.3\" })\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n</code></pre> To work around this, you can either generate a Github access token and provide it via the <code>GITHUB_TOKEN</code> environment variable, or to do this dynamically with the Github CLI, you can run a command such as <code>$ gh auth token | GITHUB_TOKEN=$(cat) git cliff v1.0.2..v1.2.4</code></p>"},{"location":"developer-guide/#documentation-best-practices","title":"Documentation Best Practices","text":"<p>When contributing to documentation:</p> <ol> <li>Write in Markdown: Use standard Markdown with MkDocs Material extensions</li> <li>Use admonitions: Highlight important information with note/warning/tip boxes    <pre><code>!!! note \"Important Information\"\n    This is a note with important information.\n</code></pre></li> <li> <p>Code blocks: Always specify language for syntax highlighting    <pre><code>```python\ndef example():\n    pass\n```\n</code></pre>    will render as:    <pre><code>def example():\n    pass\n</code></pre></p> </li> <li> <p>Link to code: Use relative links for internal documentation</p> </li> <li>Test locally: Always run <code>mkdocs serve</code> to preview changes</li> <li>Keep synchronized: Ensure README.md and docs/index.md stay in sync for the user guide</li> </ol>"},{"location":"developer-guide/#mkdocs-configuration","title":"MkDocs Configuration","text":"<p>The site is configured in <code>mkdocs.yml</code>:</p> <pre><code>site_name: FIT File Faker\ntheme:\n  name: material\n  # ... theme configuration\n\nnav:\n  - Home: index.md\n  - Developer Guide: developer-guide.md\n  - API Reference: api.md\n  - Changelog: changelog.md\n\nplugins:\n  - search                      # Built-in search\n  - minify:                     # Minify HTML/CSS/JS\n    ...\n  - autorefs                    # cross reference support\n  - mkdocstrings:               # auto generation of API docs\n    ...\n</code></pre> <p>Key features:</p> <ul> <li>Material theme: Modern, responsive design</li> <li>Search: Built-in search functionality</li> <li>Minification: Optimized HTML/CSS/JS output</li> <li>Code highlighting: Syntax highlighting for all code blocks</li> <li>Navigation: Organized sidebar navigation</li> </ul>"},{"location":"developer-guide/#troubleshooting-documentation","title":"Troubleshooting Documentation","text":""},{"location":"developer-guide/#local-build-fails","title":"Local build fails","text":"<pre><code># Ensure dependencies are installed\nuv sync --group docs\n\n# Clear MkDocs cache\nrm -rf site/\n\n# Rebuild\nmkdocs build\n</code></pre>"},{"location":"developer-guide/#changes-not-appearing-on-github-pages","title":"Changes not appearing on GitHub Pages","text":"<ol> <li>Check the GitHub Actions workflow status</li> <li>Ensure the <code>gh-pages</code> branch exists</li> <li>Verify GitHub Pages is enabled in repository settings</li> <li>Wait a few minutes for deployment to propagate</li> </ol>"},{"location":"developer-guide/#changelog-not-updating","title":"Changelog not updating","text":"<ol> <li>Ensure commits follow conventional commit format</li> <li>Check git-cliff configuration in <code>pyproject.toml</code> under <code>[tool.git-cliff.*]</code> sections</li> <li>Verify the release workflow completed successfully</li> </ol>"},{"location":"developer-guide/#resources","title":"Resources","text":"<ul> <li>GitHub Repository: jat255/Fit-File-Faker</li> <li>PyPI Package: fit-file-faker</li> <li>Issue Tracker: GitHub Issues</li> <li>pytest Documentation: https://docs.pytest.org/</li> <li>GitHub Actions: <code>.github/workflows/</code></li> </ul>"},{"location":"developer-guide/#getting-help","title":"Getting Help","text":"<p>If you need help:</p> <ol> <li>Check the documentation</li> <li>Search existing issues</li> <li>Create a new issue</li> </ol> <p>Note</p> <p>As this is a side-project provided for free, support times may vary \ud83d\ude05.</p>"}]}